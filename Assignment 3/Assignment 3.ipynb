{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cca6152",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "af0fce0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.initializers import RandomNormal\n",
    "from tensorflow.keras import initializers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "46836cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f8e4fa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape((60000, 28, 28, 1))\n",
    "x_test = x_test.reshape((10000, 28, 28, 1))\n",
    "\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "eee0151b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "86cce1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "Baseline = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28,28)),\n",
    "    tf.keras.layers.Dense(1024, activation=\"relu\", kernel_initializer=tf.keras.initializers.HeNormal()),\n",
    "    tf.keras.layers.Dense(1024, activation=\"relu\", kernel_initializer=tf.keras.initializers.HeNormal()),\n",
    "    tf.keras.layers.Dense(1024, activation=\"relu\", kernel_initializer=tf.keras.initializers.HeNormal()),\n",
    "    tf.keras.layers.Dense(1024, activation=\"relu\", kernel_initializer=tf.keras.initializers.HeNormal()),\n",
    "    tf.keras.layers.Dense(1024, activation=\"relu\", kernel_initializer=tf.keras.initializers.HeNormal()),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "\n",
    "])\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "metrics = [\"accuracy\"]\n",
    "Baseline.compile(loss=loss , optimizer=opt, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "74765f10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "120/120 [==============================] - 8s 55ms/step - loss: 0.3208 - accuracy: 0.9038 - val_loss: 0.1003 - val_accuracy: 0.9686\n",
      "Epoch 2/50\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.0765 - accuracy: 0.9762 - val_loss: 0.0793 - val_accuracy: 0.9748\n",
      "Epoch 3/50\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.0469 - accuracy: 0.9850 - val_loss: 0.0739 - val_accuracy: 0.9785\n",
      "Epoch 4/50\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.0329 - accuracy: 0.9893 - val_loss: 0.0741 - val_accuracy: 0.9780\n",
      "Epoch 5/50\n",
      "120/120 [==============================] - 6s 54ms/step - loss: 0.0274 - accuracy: 0.9913 - val_loss: 0.0818 - val_accuracy: 0.9781\n",
      "Epoch 6/50\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.0250 - accuracy: 0.9922 - val_loss: 0.0846 - val_accuracy: 0.9789\n",
      "Epoch 7/50\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.0232 - accuracy: 0.9923 - val_loss: 0.1010 - val_accuracy: 0.9758\n",
      "Epoch 8/50\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.0198 - accuracy: 0.9937 - val_loss: 0.0857 - val_accuracy: 0.9780\n",
      "Epoch 9/50\n",
      "120/120 [==============================] - 7s 54ms/step - loss: 0.0140 - accuracy: 0.9952 - val_loss: 0.0826 - val_accuracy: 0.9806\n",
      "Epoch 10/50\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.0156 - accuracy: 0.9949 - val_loss: 0.0883 - val_accuracy: 0.9796\n",
      "Epoch 11/50\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.0159 - accuracy: 0.9952 - val_loss: 0.1031 - val_accuracy: 0.9764\n",
      "Epoch 12/50\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.0154 - accuracy: 0.9956 - val_loss: 0.0857 - val_accuracy: 0.9822\n",
      "Epoch 13/50\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.0090 - accuracy: 0.9971 - val_loss: 0.0933 - val_accuracy: 0.9810\n",
      "Epoch 14/50\n",
      "120/120 [==============================] - 6s 54ms/step - loss: 0.0110 - accuracy: 0.9967 - val_loss: 0.0857 - val_accuracy: 0.9825\n",
      "Epoch 15/50\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.0136 - accuracy: 0.9960 - val_loss: 0.0936 - val_accuracy: 0.9793\n",
      "Epoch 16/50\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.0830 - val_accuracy: 0.9810\n",
      "Epoch 17/50\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.0110 - accuracy: 0.9967 - val_loss: 0.0806 - val_accuracy: 0.9815\n",
      "Epoch 18/50\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.0094 - accuracy: 0.9971 - val_loss: 0.0978 - val_accuracy: 0.9813\n",
      "Epoch 19/50\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.0094 - accuracy: 0.9973 - val_loss: 0.1014 - val_accuracy: 0.9793\n",
      "Epoch 20/50\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.0091 - accuracy: 0.9974 - val_loss: 0.0906 - val_accuracy: 0.9829\n",
      "Epoch 21/50\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.0924 - val_accuracy: 0.9825\n",
      "Epoch 22/50\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.0091 - accuracy: 0.9974 - val_loss: 0.1002 - val_accuracy: 0.9804\n",
      "Epoch 23/50\n",
      "120/120 [==============================] - 6s 52ms/step - loss: 0.0114 - accuracy: 0.9968 - val_loss: 0.0916 - val_accuracy: 0.9807\n",
      "Epoch 24/50\n",
      "120/120 [==============================] - 6s 52ms/step - loss: 0.0099 - accuracy: 0.9971 - val_loss: 0.1108 - val_accuracy: 0.9806\n",
      "Epoch 25/50\n",
      "120/120 [==============================] - 6s 54ms/step - loss: 0.0089 - accuracy: 0.9977 - val_loss: 0.0996 - val_accuracy: 0.9833\n",
      "Epoch 26/50\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.0962 - val_accuracy: 0.9810\n",
      "Epoch 27/50\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.0990 - val_accuracy: 0.9822\n",
      "Epoch 28/50\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.0814 - val_accuracy: 0.9835\n",
      "Epoch 29/50\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.0054 - accuracy: 0.9985 - val_loss: 0.0966 - val_accuracy: 0.9821\n",
      "Epoch 30/50\n",
      "120/120 [==============================] - 7s 54ms/step - loss: 0.0093 - accuracy: 0.9975 - val_loss: 0.0909 - val_accuracy: 0.9827\n",
      "Epoch 31/50\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.0077 - accuracy: 0.9980 - val_loss: 0.0988 - val_accuracy: 0.9814\n",
      "Epoch 32/50\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.1086 - val_accuracy: 0.9820\n",
      "Epoch 33/50\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.0104 - accuracy: 0.9973 - val_loss: 0.0914 - val_accuracy: 0.9832\n",
      "Epoch 34/50\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.0871 - val_accuracy: 0.9824\n",
      "Epoch 35/50\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.0100 - accuracy: 0.9973 - val_loss: 0.0904 - val_accuracy: 0.9820\n",
      "Epoch 36/50\n",
      "120/120 [==============================] - 6s 54ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.1024 - val_accuracy: 0.9833\n",
      "Epoch 37/50\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.0999 - val_accuracy: 0.9838\n",
      "Epoch 38/50\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.1055 - val_accuracy: 0.9788\n",
      "Epoch 39/50\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.0952 - val_accuracy: 0.9803\n",
      "Epoch 40/50\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.0072 - accuracy: 0.9981 - val_loss: 0.1117 - val_accuracy: 0.9806\n",
      "Epoch 41/50\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.1119 - val_accuracy: 0.9837\n",
      "Epoch 42/50\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.1092 - val_accuracy: 0.9846\n",
      "Epoch 43/50\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.1147 - val_accuracy: 0.9820\n",
      "Epoch 44/50\n",
      "120/120 [==============================] - 7s 54ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.1145 - val_accuracy: 0.9832\n",
      "Epoch 45/50\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.0068 - accuracy: 0.9984 - val_loss: 0.0857 - val_accuracy: 0.9850\n",
      "Epoch 46/50\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.1135 - val_accuracy: 0.9820\n",
      "Epoch 47/50\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.0074 - accuracy: 0.9981 - val_loss: 0.0997 - val_accuracy: 0.9838\n",
      "Epoch 48/50\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.0084 - accuracy: 0.9977 - val_loss: 0.1006 - val_accuracy: 0.9831\n",
      "Epoch 49/50\n",
      "120/120 [==============================] - 6s 54ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.1220 - val_accuracy: 0.9819\n",
      "Epoch 50/50\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.0073 - accuracy: 0.9980 - val_loss: 0.1092 - val_accuracy: 0.9831\n"
     ]
    }
   ],
   "source": [
    "Baseline_model=Baseline.fit(x_train, y_train, batch_size=500, epochs=50,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "840c17ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weight_matrix = [Baseline.layers[i].get_weights()[0] for i in range(1,len(Baseline.layers)-1)]\n",
    "bias_matrix = [Baseline.layers[i].get_weights()[1] for i in range(1,len(Baseline.layers)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "da2b46d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_matrix = [Baseline.layers[i].get_weights()[0] for i in range(1,len(Baseline.layers))]\n",
    "b_matrix = [Baseline.layers[i].get_weights()[1] for i in range(1,len(Baseline.layers))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "af45c4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_svd(layer,k,j):\n",
    "    if isinstance(layer, tf.keras.layers.Dense):\n",
    "        weights, biases = weight_matrix[j],bias_matrix[j]\n",
    "        s, u, v = tf.linalg.svd(weights)\n",
    "        u = u[:, :k]\n",
    "        s = s[:k]\n",
    "        v = v[:, :k]\n",
    "        new_weights = tf.matmul(u, tf.matmul(tf.linalg.diag(s), tf.transpose(v)))\n",
    "        layer.set_weights([new_weights, biases])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "21eea61a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in SVDed model (D=10): 48850\n",
      "Parameter reduction ratio compared to baseline (D=10): 102.61\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.5608 - accuracy: 0.7062\n",
      "Number of parameters in SVDed model (D=20): 97700\n",
      "Parameter reduction ratio compared to baseline (D=20): 51.30\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3329 - accuracy: 0.9202\n",
      "Number of parameters in SVDed model (D=50): 244250\n",
      "Parameter reduction ratio compared to baseline (D=50): 20.52\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.1122 - accuracy: 0.9796\n",
      "Number of parameters in SVDed model (D=100): 488500\n",
      "Parameter reduction ratio compared to baseline (D=100): 10.26\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0981 - accuracy: 0.9829\n",
      "Number of parameters in SVDed model (D=200): 977000\n",
      "Parameter reduction ratio compared to baseline (D=200): 5.13\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.1000 - accuracy: 0.9830\n",
      "Number of parameters in SVDed model (D=1024): 5002240\n",
      "Parameter reduction ratio compared to baseline (D=1024): 1.00\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.1092 - accuracy: 0.9831\n"
     ]
    }
   ],
   "source": [
    "accuracy =[]\n",
    "baseline_params = sum([tf.reduce_prod(var.shape) for var in Baseline.trainable_variables])\n",
    "D_values = [10, 20, 50, 100, 200, 1024]\n",
    "param = []\n",
    "param_ratio = []\n",
    "for j in range(6):\n",
    "    svded_params = 0\n",
    "    for i in range(1,len(Baseline.layers) - 1):\n",
    "        apply_svd(Baseline.layers[i],D_values[j],i-1)\n",
    "        layer = Baseline.layers[i]\n",
    "        weights, _ = layer.get_weights()\n",
    "        svded_params += weights.shape[0] * D_values[j] + D_values[j] \n",
    "    param.append(svded_params)\n",
    "    param_ratio.append(baseline_params / svded_params)\n",
    "    print(f\"Number of parameters in SVDed model (D={D_values[j]}):\", svded_params)\n",
    "    print(f\"Parameter reduction ratio compared to baseline (D={D_values[j]}): {baseline_params / svded_params:.2f}\")\n",
    "\n",
    "    accuracy.append(Baseline.evaluate(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "33471491",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "for i in range(6):\n",
    "    l.append(accuracy[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3f70dbb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABSgAAAPbCAYAAABfR2UFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAABh0klEQVR4nO3dfZyVdZ0//veZM8NwI4w3JANBiGUCUmaoCEq73Yialu5+t6hvUrpa2VpK9ui7y6rb6q+NrHS9p6+ZmpsJllm2XzWxWtOHpklgJuRNmYM6SJAygwrMOXP9/pg5B6a5kYE51zVwns/H4zyCa65zzeeM1wX66v3+vHNJkiQBAAAAAJCBmqwXAAAAAABULwElAAAAAJAZASUAAAAAkBkBJQAAAACQGQElAAAAAJAZASUAAAAAkBkBJQAAAACQGQElAAAAAJCZ2qwXMBi1t7fHCy+8ECNHjoxcLpf1cgAAAABgl5IkSbS2tsa4ceOipqbvGkkBZQ9eeOGFmDBhQtbLAAAAAIBd2urVq2P8+PF9niOg7MHIkSMjouMHOGrUqIxXAwAAAAC7lpaWlpgwYUI5Z+uLgLIHpbbuUaNGCSgBAAAAYAdtz/aJhuQAAAAAAJkRUAIAAAAAmRFQAgAAAACZEVACAAAAAJkRUAIAAAAAmRFQAgAAAACZEVACAAAAAJkRUAIAAAAAmRFQAgAAAACZEVACAAAAAJkRUAIAAAAAmRFQAgAAAACZEVACAAAAAJkRUAIAAAAAmRFQAgAAAACZEVACAAAAAJkRUAIAAAAAmRFQAgAAAACZEVACAAAAAJkRUAIAAAAAmRFQAgAAAACZEVACAAAAAJkRUAIAAAAAmRFQAgAAAACZEVACAAAAAJkRUAIAAAAAmRFQAgAAAACZEVACAAAAAJkRUAIAAAAAmRFQAgAAAACZEVACAAAAAJkRUAIAAAAAmRFQAgAAAACZEVACAAAAAJkRUAIAAAAAmRFQAgAAAACZEVACAAAAAJmpzXoBALuKJEkiSTp/Xfp9v6/Rz/P7+R36e/1KXruSa+//z72fa+n39St38UrfA/1a+mD6OUb/fzb9OX2wrX1QPR9V8udMx/X7c+3B9Xz05ztU8ueyY9ev4NoH2T1WyWvv0n/O9Pv6/XzDrvx89OMNg+lZ7XxDJU7tON/zMSBvqPjfq/4e7lFNLhdzDmrs7zfY7QgoIQPF9iSeWfdK/H5NS/y+uTWeWtsam9ray6FXSZJs/UsiSbb+oZhE0vm10ol/dV75/UnnNcunlX/T9XjyV9fvvo6evm+XgK7P77tNsJdsPae3dXQ93vvn2vpz6Xsd2/4su/4sevu+Xd8HAAAAlTCsLh+r/r9js15G5gSUUGEvvbIlVnUGkb9f0xKrmlvjyRdbY3OhPeulAQw6uVw/z+/39bf/Hf2/dj/P7+936Mfpg23t/bl+Jf+Z7sj1K/tzr9zPMaJ/66n0z7G/a+/Pd6j8nxv9vf5gWnu/f/D9uHaFz6/gnzMd1+/PtQfPnzP9PX2wPduVfD76q5I/m135+ej//Tt47rHB9u8Q23v5+tp8P6+8exJQwgBpK7bHH/68MX7f3NolkHyxZXOP5w+ry8eBjSNjytiR8dYxI2PU0LqI6PhDrPQHWS5yXf5Qy+W2/lWUy239i6nj19v+AZjb5ho9vG+b60df5/3V9Usn5nq4/l+f13Gol/Oir8/4V9+3l3WUrt/182/n9V/nvNKle/6+PfyMKv4vIP29/q4bwFTyX0QH09p31X952pG1AAAAvB4BJfRTkiTx542bywFkRyDZGk+vbY22Ys/9wG/ae3hMbhwZU8aOiiljR8bkxlHxpr2HR02N/9AHAAAAqpuAEvqwqa0YT6/dGKuaW+L3a7YGkutf2dLj+SPra2NyZwBZ+t8DG0fGHvUeNQAAAICeSE0gOqoimzdsKu8R+fs1rfH75pb447pXotjevSqyJhex3+gRMaVxVLkycvLYkfHGPYdpfwQAAADoBwElVefVLYV48sWN8fvOqshSdeSG19p6PH/P4XUdQeTYkeX/PWDfkTFsiI1sAQAAAHaWgJLdVnt7Es+99FqXgTW/X9Maf1r/SiQ9bBVZW5OLN79hjy4t2lMaR8WYUfWqIgEAAAAqREDJbqF1U1s8saZjWE2pMvKJNa2xcXOhx/NH71EfU8Z2tmY3dgSSb953RNTXqooEAAAASJOAkl1KsT2JZ9e/Um7NXtVZGfncS6/1eP6QfE0cMGaPmNy4dXr2gY0j4w0j61NeOQAAAAA9EVCyS7j54aZY/HBTPPFia2xqa+/xnLENQzuqITurIqeOHRX7jR4RdfmalFcLAAAAwPYSUDLoFYrt8e+3Px6bCx3B5NC6mjiwcVRMaRzZJZDcc/iQjFcKAAAAQH8JKBn0/rjuldhcaI8RQ/Lxk88dFRP3GRH5GkNrAAAAAHYHAkoGvVXNLRERMXnsqNj/DXtkvBoAAAAABpLN+Rj0Vr7QEVBOGTsy45UAAAAAMNAElAx6KzsrKKeObch4JQAAAAAMNAElg96q5taIUEEJAAAAsDsSUDKorW3dFOs2bo6aXMTkxlFZLwcAAACAASagZFArVU/uN3pEDBuSz3g1AAAAAAw0ASWD2tYBOaonAQAAAHZHAkoGtVXlATkCSgAAAIDdkYCSQU1ACQAAALB7E1AyaG1qK8Yf/rwxIrR4AwAAAOyuBJQMWk++2BrtScTeI4bEmFH1WS8HAAAAgAoQUDJoldq7p4wdGblcLuPVAAAAAFAJAkoGrdIEb/tPAgAAAOy+BJQMWquaWyPC/pMAAAAAuzMBJYNSkiTbtHgLKAEAAAB2VwJKBqXnXnotWjcXYki+Jt78hj2yXg4AAAAAFSKgZFBa2Vk9+ZZ994ghtW5TAAAAgN2V5IdBqTwgZ5z2bgAAAIDdmYCSQcn+kwAAAADVQUDJoLRqTSmgHJnxSgAAAACoJAElg07LprZY/ZfXIiJiqgpKAAAAgN2agJJB5/fNrRERMa5haOw5fEjGqwEAAACgkgSUDDorX9gQEfafBAAAAKgGAkoGnVWdFZQmeAMAAADs/gSUDDpbB+QIKAEAAAB2dwJKBpVCsT1+v6azglJACQAAALDbE1AyqDyz7pXYUmiPEUPy8aa9h2e9HAAAAAAqTEDJoLKyuaO9+8DGkVFTk8t4NQAAAABUmoCSQaUUUBqQAwAAAFAdBJQMKqUJ3gbkAAAAAFQHASWDysoXOisoBZQAAAAAVUFAyaDx59bNsW7j5sjlOvagBAAAAGD3J6Bk0FjVuf/kpH1GxPAhtRmvBgAAAIA0CCgZNEoDcqYYkAMAAABQNQSUDBqlCkr7TwIAAABUDwElg0ZpQM6UsfafBAAAAKgWAkoGhU1txfjjulciImLq2IaMVwMAAABAWgSUDApPvbgxiu1J7DW8LsaMqs96OQAAAACkREDJoLCyeUNEREwdNypyuVzGqwEAAAAgLQJKBoVVza0RETGl0YAcAAAAgGoioGRQ2DogR0AJAAAAUE0ElGQuSZJYtaYjoJw6TkAJAAAAUE0ElGTuuZdei9ZNhajL5+LNb9gj6+UAAAAAkCIBJZlb2dxRPXnAviNjSK1bEgAAAKCaSIPI3Kpm+08CAAAAVCsBJZnbGlCOzHglAAAAAKRNQEnmSi3eBuQAAAAAVB8BJZlq2dQWq//yWkRETNXiDQAAAFB1BJRk6vfNrRERMbZhaOw5fEjGqwEAAAAgbQJKMlXaf1L1JAAAAEB1ElCSKRO8AQAAAKqbgJJMGZADAAAAUN0ElGSmUGyPJ9Z07EGpghIAAACgOgkoycyf1r8SmwvtMXxIPibuPTzr5QAAAACQAQElmXn8hY727smNI6OmJpfxagAAAADIgoCSzKxq1t4NAAAAUO0ElGTGgBwAAAAABJRkZlVnQKmCEgAAAKB6CSjJxJ9bN8efWzdHLtexByUAAAAA1UlASSZK1ZOT9hkRw4fUZrwaAAAAALIioCQT2rsBAAAAiBBQkpGV5YBSezcAAABANRNQkolVJngDAAAAEAJKMrCprRh/+PMrEaHFGwAAAKDaCShJ3VMvboxiexJ7Da+LxlFDs14OAAAAABkSUJK6bQfk5HK5jFcDAAAAQJYElKRupQneAAAAAHQSUJK6UkA5VUAJAAAAUPUElKQqSZIuLd4AAAAAVDcBJal67qXXonVTIeryuXjLvntkvRwAAAAAMiagJFWl6sm37DsyhtS6/QAAAACqnYSIVK1qbo2IiCljR2a8EgAAAAAGAwElqVrZvCEiDMgBAAAAoIOAklSVKigFlAAAAABECChJUeumtmj6y6sRYYI3AAAAAB0ElKTm92s6qifHNgyNvUYMyXg1AAAAAAwGAkpSU5rgrXoSAAAAgBIBJalZ+UJHQGn/SQAAAABKBJSkRgUlAAAAAH9NQEkqCsX28h6UU8aOzHg1AAAAAAwWAkpS8af1r8TmQnsMH5KPifuMyHo5AAAAAAwSAkpSsbK5o3rywMaRka/JZbwaAAAAAAYLASWpMCAHAAAAgJ4IKEmFATkAAAAA9CTzgPLqq6+OSZMmxdChQ2P69Olx33339Xn+VVddFVOmTIlhw4bFgQceGDfeeGOXr99www2Ry+W6vTZt2lTJj8HrEFACAAAA0JPaLL/5kiVLYv78+XH11VfHkUceGf/3//7fOO6442LlypXxpje9qdv5ixYtigULFsS3vvWtOOyww+Lhhx+OT37yk7HXXnvFBz7wgfJ5o0aNiieeeKLLe4cOHVrxz0PP1m3cHGtbN0cuFzG50QRvAAAAALbKNKC85JJL4rTTTovTTz89IiIuvfTS+OlPfxqLFi2KhQsXdjv/v/7rv+LTn/50zJ07NyIi9t9///jVr34VF110UZeAMpfLRWNjYzofgtdVqp7cb58RMaI+01sOAAAAgEEmsxbvLVu2xLJly2LOnDldjs+ZMyceeOCBHt+zefPmbpWQw4YNi4cffjja2trKxzZu3BgTJ06M8ePHxwknnBDLly/vcy2bN2+OlpaWLi8Gztb2btWTAAAAAHSVWUC5bt26KBaLMWbMmC7Hx4wZE2vWrOnxPcccc0xce+21sWzZskiSJB555JG47rrroq2tLdatWxcREZMnT44bbrghbr/99rj55ptj6NChceSRR8ZTTz3V61oWLlwYDQ0N5deECRMG7oNigjcAAAAAvcp8SE4ul+vy+yRJuh0rOf/88+O4446LI444Iurq6uLEE0+MU045JSIi8vl8REQcccQRcfLJJ8fBBx8cs2fPjltuuSXe+ta3xhVXXNHrGhYsWBAbNmwov1avXj0wH46IiFjV3BoRBuQAAAAA0F1mAeXo0aMjn893q5Zcu3Ztt6rKkmHDhsV1110Xr776avzpT3+Kpqam2G+//WLkyJExevToHt9TU1MThx12WJ8VlPX19TFq1KguLwbGprZiPP3njRERMXWcnysAAAAAXWUWUA4ZMiSmT58eS5cu7XJ86dKlMWvWrD7fW1dXF+PHj498Ph+LFy+OE044IWpqev4oSZLEihUrYuzYsQO2drbf02s3RrE9iT2H10XjKJPUAQAAAOgq05HK55xzTsybNy8OPfTQmDlzZlxzzTXR1NQUZ5xxRkR0tF4///zzceONN0ZExJNPPhkPP/xwzJgxI1566aW45JJL4ne/+1185zvfKV/zggsuiCOOOCIOOOCAaGlpicsvvzxWrFgRV111VSafsdqtLA3IaRzVa+s+AAAAANUr04By7ty5sX79+rjwwgujubk5pk2bFnfccUdMnDgxIiKam5ujqampfH6xWIyLL744nnjiiairq4t3v/vd8cADD8R+++1XPufll1+OT33qU7FmzZpoaGiIQw45JH75y1/G4YcfnvbHI7YZkKO9GwAAAIAe5JIkSbJexGDT0tISDQ0NsWHDBvtR7qS5//fBeOiZv8Q3PnRw/MP08VkvBwAAAIAU9Cdfy3yKN7uvJEnKLd5TTfAGAAAAoAcCSirm+Zdfi9ZNhajL5+It++6R9XIAAAAAGIQElFTMqubWiIh48xv2iCG1bjUAAAAAupMaUTEG5AAAAADwegSUVMwq+08CAAAA8DoElFTMqjUdAeUUASUAAAAAvRBQUhGtm9ri2fWvRoSAEgAAAIDeCSipiCfWdAzIaRw1NPYeMSTj1QAAAAAwWAkoqYiVzQbkAAAAAPD6BJRURGlAzpSxIzNeCQAAAACDmYCSiljZ3NHibf9JAAAAAPoioGTAFduTeKJzgvdUASUAAAAAfRBQMuCeWfdKbGprj2F1+Zi4z4islwMAAADAICagZMCV9p+cPHZk5GtyGa8GAAAAgMFMQMmAW1kekKO9GwAAAIC+CSgZcKsElAAAAABsJwElA27lCwbkAAAAALB9BJQMqPUbN8fa1s2Ry0VMbhyZ9XIAAAAAGOQElAyoVc2tERExce/hMaK+NuPVAAAAADDYCSgZUCubN0RExNRx2rsBAAAAeH0CSgZUqYJySqOAEgAAAIDXJ6BkQJUH5KigBAAAAGA7CCgZMJsLxfjDnzdGRMQUE7wBAAAA2A4CSgbMUy9ujEJ7Eg3D6mJsw9CslwMAAADALkBAyYBZ2dzZ3j12VORyuYxXAwAAAMCuQEDJgFnVGVBq7wYAAABgewkoGTClgNKAHAAAAAC2l4CSAZEkSXmC95SxIzNeDQAAAAC7CgElA+KFDZuiZVMhamty8ZZ998h6OQAAAADsIgSUDIhS9eRb9t0j6mvzGa8GAAAAgF2FgJIBsWqbCd4AAAAAsL0ElAwIA3IAAAAA2BECSgbEyubSgBwBJQAAAADbT0DJTtu4uRDPrn81IgSUAAAAAPSPgJKd9sSajurJxlFDY+8RQzJeDQAAAAC7EgElO600wXvK2JEZrwQAAACAXY2Akp22srk1IrR3AwAAANB/Akp22koTvAEAAADYQQJKdkqxPSnvQamCEgAAAID+ElCyU/60/pXY1NYew+rysd8+I7JeDgAAAAC7GAElO6U0IOfAxpGRr8llvBoAAAAAdjUCSnbKqmbt3QAAAADsOAElO8WAHAAAAAB2hoCSnVKqoJw6dmTGKwEAAABgVySgZIet37g5XmzZHLlcxIGNKigBAAAA6D8BJTtsVXNrRERM3Ht47FFfm/FqAAAAANgVCSjZYQbkAAAAALCzBJTssK37TwooAQAAANgxAkp22EoVlAAAAADsJAElO2RzoRhPr90YERFTxgkoAQAAANgxAkp2yFMvboxCexINw+piXMPQrJcDAAAAwC5KQMkO2TogZ2TkcrmMVwMAAADArkpAyQ5Z1dwaERFTxzZkvBIAAAAAdmUCSnbIyuYNEdFRQQkAAAAAO0pASb8lSVKuoDTBGwAAAICdIaCk317YsCk2vNYWtTW5OGDMHlkvBwAAAIBdmICSflv1QseAnLfsu0fU1+YzXg0AAAAAuzIBJf1WmuA9VXs3AAAAADtJQEm/rewMKO0/CQAAAMDOElDSb6sElAAAAAAMEAEl/bJxcyGe/curERExZezIjFcDAAAAwK5OQEm/PLGmJZIkYsyo+thnj/qslwMAAADALk5ASb+sbG6NCO3dAAAAAAwMASX9svIFE7wBAAAAGDgCSvrFgBwAAAAABpKAku1WbE/iiTUdLd5TxwkoAQAAANh5Akq225/WvxKvtRVjaF1N7LfPiKyXAwAAAMBuQEDJdiu1dx/YOCryNbmMVwMAAADA7kBAyXYrBZQG5AAAAAAwUASUbLetE7xHZrwSAAAAAHYXAkq226pmA3IAAAAAGFgCSrbLX17ZEmtaNkVExx6UAAAAADAQBJRsl9L+kxP3GR571NdmvBoAAAAAdhcCSraLATkAAAAAVIKAku1SGpAzRUAJAAAAwAASULJdVjYLKAEAAAAYeAJKXtfmQjGeXrsxIkzwBgAAAGBgCSh5XU+v3RiF9iRGDa2NcQ1Ds14OAAAAALsRASWva1Vza0R0VE/mcrmMVwMAAADA7kRAyesyIAcAAACAShFQ8rpWGZADAAAAQIUIKOlTkiSxak1HQDlVQAkAAADAABNQ0qfmDZvi5VfborYmFweM2SPr5QAAAACwmxFQ0qc//HljRETsN3pE1NfmM14NAAAAALsbASV92tzWHhERe9TXZrwSAAAAAHZHAkr6VGhPIiKitiaX8UoAAAAA2B0JKOlTob2jgrI2L6AEAAAAYOAJKOlTsVxB6VYBAAAAYOBJnehTW7EzoFRBCQAAAEAFCCjpU7HU4m0PSgAAAAAqQEBJn0pDcvICSgAAAAAqQEBJnwrlFm+3CgAAAAADT+pEnwrlITkqKAEAAAAYeAJK+rR1D0q3CgAAAAADT+pEn8pTvFVQAgAAAFABAkr6VCwNyckLKAEAAAAYeAJK+lQodrR416mgBAAAAKACBJT0qTQkJ28PSgAAAAAqQOpEn0ot3rVavAEAAACoAAElfTIkBwAAAIBKElDSp2J7xx6UAkoAAAAAKkFASZ/ayi3ebhUAAAAABp7UiT4Vi6UhOSooAQAAABh4Akr6VJrircUbAAAAgEoQUNKnQmkPSi3eAAAAAFSA1Ik+qaAEAAAAoJIElPSptAdlbV5ACQAAAMDAE1DSp3KLtwpKAAAAACpAQEmfSi3e+Rq3CgAAAAADT+pEnwqdLd51WrwBAAAAqAABJX0qtXjntXgDAAAAUAECSvpUNMUbAAAAgAoSUNKnttIUb3tQAgAAAFABUif6VKqgzNuDEgAAAIAKEFDSp7Zixx6UdSooAQAAAKgAqRN9KldQ2oMSAAAAgAoQUNKn8pAcLd4AAAAAVICAkj61tXe0eJviDQAAAEAlCCjpU9EUbwAAAAAqSOpEnwpavAEAAACoIAElfSoHlFq8AQAAAKgAASV9KhQ79qA0xRsAAACAShBQ0qdSBWVd3q0CAAAAwMCTOtGnUkCpghIAAACAShBQ0qeiPSgBAAAAqCABJb1KkmRrQKnFGwAAAIAKkDrRq1J7d4QWbwAAAAAqQ0BJrwrFrQFlXV5ACQAAAMDAE1DSq0J7e/nXKigBAAAAqAQBJb0qbtPiXVvjVgEAAABg4Emd6FVbZ4t3LqeCEgAAAIDKEFDSq/IEb+EkAAAAABUioKRXpT0oVU8CAAAAUCkCSnpVmuJdZ/9JAAAAACpE8kSvCp0t3vm8CkoAAAAAKkNASa9KLd4meAMAAABQKZInelVq8TYkBwAAAIBKEVDSq9IUb0NyAAAAAKgUASW9KrV419mDEgAAAIAKEVDSq1KLtwpKAAAAACpFQEmvSlO86/JuEwAAAAAqI/Pk6eqrr45JkybF0KFDY/r06XHffff1ef5VV10VU6ZMiWHDhsWBBx4YN954Y7dzbr311pg6dWrU19fH1KlT47bbbqvU8ndrBXtQAgAAAFBhmQaUS5Ysifnz58e5554by5cvj9mzZ8dxxx0XTU1NPZ6/aNGiWLBgQfz7v/97PP7443HBBRfEmWeeGT/5yU/K5zz44IMxd+7cmDdvXjz66KMxb968+PCHPxwPPfRQWh9rt1Hs3IPSFG8AAAAAKiWXJEmS1TefMWNGvPOd74xFixaVj02ZMiVOOumkWLhwYbfzZ82aFUceeWR8/etfLx+bP39+PPLII3H//fdHRMTcuXOjpaUl7rzzzvI5xx57bOy1115x8803b9e6WlpaoqGhITZs2BCjRo3a0Y+3y/vp42vi0/+1LKZP3Ctu/cysrJcDAAAAwC6iP/laZhWUW7ZsiWXLlsWcOXO6HJ8zZ0488MADPb5n8+bNMXTo0C7Hhg0bFg8//HC0tbVFREcF5V9f85hjjun1mqXrtrS0dHkRUdTiDQAAAECFZRZQrlu3LorFYowZM6bL8TFjxsSaNWt6fM8xxxwT1157bSxbtiySJIlHHnkkrrvuumhra4t169ZFRMSaNWv6dc2IiIULF0ZDQ0P5NWHChJ38dLuH0h6UWrwBAAAAqJTMh+Tkcl3DryRJuh0rOf/88+O4446LI444Iurq6uLEE0+MU045JSIi8vn8Dl0zImLBggWxYcOG8mv16tU7+Gl2L4Vi5x6UpngDAAAAUCGZJU+jR4+OfD7frbJx7dq13SogS4YNGxbXXXddvPrqq/GnP/0pmpqaYr/99ouRI0fG6NGjIyKisbGxX9eMiKivr49Ro0Z1eaGCEgAAAIDKyyygHDJkSEyfPj2WLl3a5fjSpUtj1qy+B7LU1dXF+PHjI5/Px+LFi+OEE06ImpqOjzJz5sxu17z77rtf95p0VygKKAEAAACorNosv/k555wT8+bNi0MPPTRmzpwZ11xzTTQ1NcUZZ5wRER2t188//3zceOONERHx5JNPxsMPPxwzZsyIl156KS655JL43e9+F9/5znfK1zz77LPjXe96V1x00UVx4oknxo9//OO45557ylO+2X7F9lKLt4ASAAAAgMrINKCcO3durF+/Pi688MJobm6OadOmxR133BETJ06MiIjm5uZoamoqn18sFuPiiy+OJ554Iurq6uLd7353PPDAA7HffvuVz5k1a1YsXrw4zjvvvDj//PPjzW9+cyxZsiRmzJiR9sfb5RXKU7ztQQkAAABAZeSSJEmyXsRg09LSEg0NDbFhw4aq3o/yW7/8Y/zHHavi7w95Y1wy9x1ZLwcAAACAXUR/8jWlcfRqawWlFm8AAAAAKkNASa8KxdIelG4TAAAAACpD8kSvShWUpngDAAAAUCkCSnpV1OINAAAAQIUJKOlVW3tHi3ddXkAJAAAAQGUIKOlVsViqoHSbAAAAAFAZkid6ZQ9KAAAAACpNQEmvCu2lKd4CSgAAAAAqQ0BJr4oqKAEAAACoMAElvWrr3IOyNu82AQAAAKAyJE/0SgUlAAAAAJUmoKRXpSE5eQElAAAAABUioKRXhWJpSI7bBAAAAIDKkDzRq4IWbwAAAAAqTEBJr8oVlAJKAAAAACpEQEmvyhWUeQElAAAAAJUhoKRXxfKQHLcJAAAAAJUheaJXhWJHQFmnxRsAAACAChFQ0qtCe8celHkBJQAAAAAVIqCkV0V7UAIAAABQYQJKetXW2eJdaw9KAAAAACpE8kSvyhWUWrwBAAAAqBABJb1q69yDsjbvNgEAAACgMiRP9KpUQWlIDgAAAACVIqCkV4WiFm8AAAAAKktASa8K5RZvASUAAAAAlSGgpFdbh+S4TQAAAACoDMkTvWortXiroAQAAACgQgSU9GprBaWAEgAAAIDKEFDSq9IelKZ4AwAAAFApAkp6VZriXZd3mwAAAABQGZInepQkSRQ6W7xVUAIAAABQKQJKetSZTUaEPSgBAAAAqBwBJT1qK7aXf12rxRsAAACACpE80aPiNiWUKigBAAAAqBQBJT0qDciJEFACAAAAUDkCSnpUaN/a4m1IDgAAAACVIqCkR8VtJnjncgJKAAAAACpDQEmP2joDSu3dAAAAAFSSgJIeFYsCSgAAAAAqT0BJj9o696CszbtFAAAAAKgc6RM9KmrxBgAAACAFAkp6VChuHZIDAAAAAJUioKRHhc4W7zot3gAAAABUkPSJHhXaVVACAAAAUHkCSnpkD0oAAAAA0iCgpEdtxdIUbwElAAAAAJUjoKRHxXKLt1sEAAAAgMqRPtGj0hTvOhWUAAAAAFSQgJIeGZIDAAAAQBoElPSo2N65B6WAEgAAAIAKElDSo7ZiaYq3WwQAAACAypE+0aPSkBxTvAEAAACoJAElPWordrR424MSAAAAgEoSUNKjcgWlFm8AAAAAKkj6RI8K5YBSBSUAAAAAlSOgpEeFzhZve1ACAAAAUEkCSnqkghIAAACANAgo6VFpD8q8PSgBAAAAqCDpEz0qVVDWafEGAAAAoIIElPSoUCxVUAooAQAAAKgcASU9KrR3DMmpy7tFAAAAAKgc6RM9KrSroAQAAACg8gSU9KhoijcAAAAAKRBQ0qO2YkeLd60hOQAAAABUkICSHhXLLd5uEQAAAAAqR/pEj9qKWrwBAAAAqDwBJT0qtmvxBgAAAKDyBJT0qGBIDgAAAAApEFDSo0K5xdstAgAAAEDlSJ/oUWlIjhZvAAAAACpJQEmPCp17UOa1eAMAAABQQQJKelRq8a7T4g0AAABABUmf6FFpSI4KSgAAAAAqSUBJj0ot3vagBAAAAKCSBJT0yBRvAAAAANIgfaJHRS3eAAAAAKRAQEmP2joDyjot3gAAAABUkICSHhU796BUQQkAAABAJQko6ZE9KAEAAABIg/SJHhU6W7xN8QYAAACgkgSU9Kg0JKdWizcAAAAAFSSgpEdtxY49KGvzbhEAAAAAKkf6RI9UUAIAAACQBgElPSrtQWmKNwAAAACVJKCkR4XOFu86Q3IAAAAAqCABJT3aWkHpFgEAAACgcqRP9KhQtAclAAAAAJUnoKRH5SE5WrwBAAAAqCABJT0qtHfsQWlIDgAAAACVJKCkm/b2JDoLKKPOHpQAAAAAVJD0iW5KA3IiIvJavAEAAACoIAEl3ZTauyMMyQEAAACgsgSUdLNtBWWtFm8AAAAAKkj6RDfF4rYBpQpKAAAAACpHQEk3bZ0t3jW5iBoBJQAAAAAVJKCkm2Jni7f2bgAAAAAqTQJFN4XOFu+86kkAAAAAKkxASTelITm1eQElAAAAAJUloKSbYucelAbkAAAAAFBpAkq6aSuWKijdHgAAAABUlgSKbrYOyVFBCQAAAEBlCSjpprQHpSE5AAAAAFSagJJuCsWOPSjrtHgDAAAAUGESKLpRQQkAAABAWgSUdFMo2oMSAAAAgHQIKOmm0N7R4l2bF1ACAAAAUFkCSropllu83R4AAAAAVJYEim7aOlu867R4AwAAAFBhAkq6KRqSAwAAAEBKBJR0Yw9KAAAAANIioKSbrVO83R4AAAAAVJYEim5KLd61WrwBAAAAqDABJd20afEGAAAAICUCSrrZWkHp9gAAAACgsiRQdFPag9IUbwAAAAAqTUBJN6Z4AwAAAJAWASXdFAzJAQAAACAlAkq62dri7fYAAAAAoLIkUHRTqqCs0+INAAAAQIUJKOmm2LkHpSE5AAAAAFSagJJuSi3edXm3BwAAAACVJYGim1KLtwpKAAAAACpNQEk3RVO8AQAAAEiJgJJu2oode1DWmuINAAAAQIVJoOimXEFpijcAAAAAFSagpJu2ohZvAAAAANIhoKSbYntHi7chOQAAAABUmoCSbgqG5AAAAACQEgEl3RRKLd55twcAAAAAlSWBohsVlAAAAACkRUBJNwV7UAIAAACQkn4HlPvtt19ceOGF0dTUVIn1MAgUOyso67R4AwAAAFBh/U6gvvCFL8SPf/zj2H///ePoo4+OxYsXx+bNmyuxNjJS2oNSBSUAAAAAldbvgPJzn/tcLFu2LJYtWxZTp06Ns846K8aOHRuf/exn4ze/+U0l1kjKSi3edXkBJQAAAACVtcM9vAcffHBcdtll8fzzz8eXvvSluPbaa+Owww6Lgw8+OK677rpIkmQg10mKSkNy8jVavAEAAACorNodfWNbW1vcdtttcf3118fSpUvjiCOOiNNOOy1eeOGFOPfcc+Oee+6J733vewO5VlJSNMUbAAAAgJT0O6D8zW9+E9dff33cfPPNkc/nY968efGf//mfMXny5PI5c+bMiXe9610DulDS09a5B2WtFm8AAAAAKqzfAeVhhx0WRx99dCxatChOOumkqKur63bO1KlT4yMf+ciALJD0FTv3oDQkBwAAAIBK63dA+cc//jEmTpzY5zkjRoyI66+/focXRbZKU7xr7UEJAAAAQIX1O4Fau3ZtPPTQQ92OP/TQQ/HII4/0ewFXX311TJo0KYYOHRrTp0+P++67r8/zb7rppjj44INj+PDhMXbs2Dj11FNj/fr15a/fcMMNkcvlur02bdrU77VVq9KQHC3eAAAAAFRavwPKM888M1avXt3t+PPPPx9nnnlmv661ZMmSmD9/fpx77rmxfPnymD17dhx33HHR1NTU4/n3339/fPzjH4/TTjstHn/88fj+978fv/71r+P000/vct6oUaOiubm5y2vo0KH9Wls1MyQHAAAAgLT0O6BcuXJlvPOd7+x2/JBDDomVK1f261qXXHJJnHbaaXH66afHlClT4tJLL40JEybEokWLejz/V7/6Vey3335x1llnxaRJk+Koo46KT3/6090qN3O5XDQ2NnZ5sf3aih17UGrxBgAAAKDS+p1A1dfXx4svvtjteHNzc9TWbv+Wllu2bIlly5bFnDlzuhyfM2dOPPDAAz2+Z9asWfHcc8/FHXfcEUmSxIsvvhg/+MEP4vjjj+9y3saNG2PixIkxfvz4OOGEE2L58uV9rmXz5s3R0tLS5VXNilq8AQAAAEhJvwPKo48+OhYsWBAbNmwoH3v55ZfjX//1X+Poo4/e7uusW7cuisVijBkzpsvxMWPGxJo1a3p8z6xZs+Kmm26KuXPnxpAhQ6KxsTH23HPPuOKKK8rnTJ48OW644Ya4/fbb4+abb46hQ4fGkUceGU899VSva1m4cGE0NDSUXxMmTNjuz7E7KlVQmuINAAAAQKX1O6C8+OKLY/Xq1TFx4sR497vfHe9+97tj0qRJsWbNmrj44ov7vYBcrmsIliRJt2MlK1eujLPOOiv+7d/+LZYtWxZ33XVXPPPMM3HGGWeUzzniiCPi5JNPjoMPPjhmz54dt9xyS7z1rW/tEmL+tVLgWnr1tMdmNSlVUNZp8QYAAACgwra/J7vTG9/4xvjtb38bN910Uzz66KMxbNiwOPXUU+OjH/1o1NXVbfd1Ro8eHfl8vlu15Nq1a7tVVZYsXLgwjjzyyPjiF78YERFvf/vbY8SIETF79uz48pe/HGPHju32npqamjjssMP6rKCsr6+P+vr67V777q40xTuvxRsAAACACut3QBkRMWLEiPjUpz61U994yJAhMX369Fi6dGn83d/9Xfn40qVL48QTT+zxPa+++mq3fS7z+XxEdFRe9iRJklixYkW87W1v26n1VpNCuYJSQAkAAABAZe1QQBnR0W7d1NQUW7Zs6XL8gx/84HZf45xzzol58+bFoYceGjNnzoxrrrkmmpqayi3bCxYsiOeffz5uvPHGiIj4wAc+EJ/85Cdj0aJFccwxx0Rzc3PMnz8/Dj/88Bg3blxERFxwwQVxxBFHxAEHHBAtLS1x+eWXx4oVK+Kqq67a0Y9aVZIkKbd424MSAAAAgErrd0D5xz/+Mf7u7/4uHnvsscjlcuXKxdK+kcVicbuvNXfu3Fi/fn1ceOGF0dzcHNOmTYs77rgjJk6cGBEdk8GbmprK559yyinR2toaV155ZXzhC1+IPffcM97znvfERRddVD7n5Zdfjk996lOxZs2aaGhoiEMOOSR++ctfxuGHH97fj1qVSuFkREStPSgBAAAAqLBc0ltvdC8+8IEPRD6fj29961ux//77x8MPPxzr16+PL3zhC/GNb3wjZs+eXam1pqalpSUaGhpiw4YNMWrUqKyXk6pNbcWYfP5dERHx+AXHxIj6HS6yBQAAAKBK9Sdf63f69OCDD8bPf/7zeMMb3hA1NTVRU1MTRx11VCxcuDDOOuusWL58+Q4vnOwVtqmg1OINAAAAQKX1u4e3WCzGHnvsEREdk7hfeOGFiIiYOHFiPPHEEwO7OlJXKLaXf10roAQAAACgwvpdQTlt2rT47W9/G/vvv3/MmDEjvva1r8WQIUPimmuuif33378SayRFKigBAAAASFO/A8rzzjsvXnnllYiI+PKXvxwnnHBCzJ49O/bZZ59YsmTJgC+QdJWG5NTW5MqDjwAAAACgUvodUB5zzDHlX++///6xcuXK+Mtf/hJ77bWXQGs30NbZ4l2b988SAAAAgMrr1x6UhUIhamtr43e/+12X43vvvbdwcjextYKy39uTAgAAAEC/9SuFqq2tjYkTJ0axWKzUeshYW7EjoLT/JAAAAABp6HeZ3HnnnRcLFiyIv/zlL5VYDxkrVVDWafEGAAAAIAX93oPy8ssvj6effjrGjRsXEydOjBEjRnT5+m9+85sBWxzpK7R37EGpghIAAACANPQ7oDzppJMqsAwGi0LRHpQAAAAApKffAeWXvvSlSqyDQaJQGpKjxRsAAACAFCiTo4vSHpRavAEAAABIQ78rKGtqaiKX6z28MuF711YoduxBWafFGwAAAIAU9DugvO2227r8vq2tLZYvXx7f+c534oILLhiwhZGNggpKAAAAAFLU74DyxBNP7HbsH/7hH+Kggw6KJUuWxGmnnTYgCyMbpSne9qAEAAAAIA0D1sc7Y8aMuOeeewbqcmRk6xRvASUAAAAAlTcgAeVrr70WV1xxRYwfP34gLkeGSkNyau1BCQAAAEAK+t3ivddee3UZkpMkSbS2tsbw4cPju9/97oAujvS1lQJKLd4AAAAApKDfAeV//ud/dgkoa2pq4g1veEPMmDEj9tprrwFdHOkrdu5BaUgOAAAAAGnod0B5yimnVGAZDBZt9qAEAAAAIEX93mjw+uuvj+9///vdjn//+9+P73znOwOyKLJT3oMybw9KAAAAACqv3ynUV7/61Rg9enS34/vuu2985StfGZBFkZ1CuwpKAAAAANLT74Dy2WefjUmTJnU7PnHixGhqahqQRZGdQrFjD0oVlAAAAACkod8p1L777hu//e1vux1/9NFHY5999hmQRZGdogpKAAAAAFLU74DyIx/5SJx11lnxi1/8IorFYhSLxfj5z38eZ599dnzkIx+pxBpJUanF2xRvAAAAANLQ7yneX/7yl+PZZ5+N9773vVFb2/H29vb2+PjHP24Pyt1AqcW7Li+gBAAAAKDy+h1QDhkyJJYsWRJf/vKXY8WKFTFs2LB429veFhMnTqzE+kiZCkoAAAAA0tTvgLLkgAMOiAMOOGAg18IgUCiW9qA0JAcAAACAyut3CvUP//AP8dWvfrXb8a9//evxoQ99aEAWRXYKhuQAAAAAkKJ+B5T33ntvHH/88d2OH3vssfHLX/5yQBZFdortHXtQ5u1BCQAAAEAK+h1Qbty4MYYMGdLteF1dXbS0tAzIoshOW2eLd50WbwAAAABS0O8Uatq0abFkyZJuxxcvXhxTp04dkEWRnaIhOQAAAACkqN9Dcs4///z4X//rf8Uf/vCHeM973hMRET/72c/ie9/7XvzgBz8Y8AWSrkJni7c9KAEAAABIQ78Dyg9+8IPxox/9KL7yla/ED37wgxg2bFgcfPDB8fOf/zxGjRpViTWSovIU77wWbwAAAAAqr98BZUTE8ccfXx6U8/LLL8dNN90U8+fPj0cffTSKxeKALpB0FU3xBgAAACBFO1wm9/Of/zxOPvnkGDduXFx55ZXx/ve/Px555JGBXBsZaCsFlKZ4AwAAAJCCflVQPvfcc3HDDTfEddddF6+88kp8+MMfjra2trj11lsNyNlNFO1BCQAAAECKtruC8v3vf39MnTo1Vq5cGVdccUW88MILccUVV1RybWSgtAdlvsYelAAAAABU3nZXUN59991x1llnxWc+85k44IADKrkmMlTQ4g0AAABAira7TO6+++6L1tbWOPTQQ2PGjBlx5ZVXxp///OdKro0MFAzJAQAAACBF2x1Qzpw5M771rW9Fc3NzfPrTn47FixfHG9/4xmhvb4+lS5dGa2trJddJSgrFjj0o8wJKAAAAAFLQ740Ghw8fHv/4j/8Y999/fzz22GPxhS98Ib761a/GvvvuGx/84AcrsUZSVKqgrMvbgxIAAACAytupFOrAAw+Mr33ta/Hcc8/FzTffPFBrIkPF9tKQHBWUAAAAAFTegJTJ5fP5OOmkk+L2228fiMuRoVKLd50hOQAAAACkQB8vXRTKFZRuDQAAAAAqTwpFF4WiKd4AAAAApEdASReF9o4WbwElAAAAAGkQUNJFaUhOrT0oAQAAAEiBgJIu2sot3m4NAAAAACpPCkUXxfKQHBWUAAAAAFSegJIuClq8AQAAAEiRgJIutg7JcWsAAAAAUHlSKLoolvegVEEJAAAAQOUJKOmirbOC0h6UAAAAAKRBQEkXpSE5dXm3BgAAAACVJ4Wii4Ip3gAAAACkSEBJWbE9iaQjn4w6U7wBAAAASIGAkrLSBO8IFZQAAAAApENASVmhc4J3RERtjVsDAAAAgMqTQlFW2n8yIqJWizcAAAAAKRBQUlbcNqDU4g0AAABACgSUlBWKHXtQ5mtykcsJKAEAAACoPAElZaUWbwNyAAAAAEiLgJKyUou39m4AAAAA0iKgpKyts8VbQAkAAABAWgSUlJUrKPNuCwAAAADSIYmirK1oD0oAAAAA0iWgpKxUQVknoAQAAAAgJQJKygrtHXtQ5vMCSgAAAADSIaCkrFCuoHRbAAAAAJAOSRRlBXtQAgAAAJAyASVl5RZvASUAAAAAKRFQUlZu8c67LQAAAABIhySKsqIWbwAAAABSJqCkrNTiXSugBAAAACAlAkrKSi3etXkBJQAAAADpEFBSViwFlDVuCwAAAADSIYmirK2oghIAAACAdAkoKSvagxIAAACAlAkoKWszxRsAAACAlAkoKSvvQZl3WwAAAACQDkkUZeUp3iooAQAAAEiJgJKyQrG0B6XbAgAAAIB0SKIoU0EJAAAAQNoElJQVSkNy8gJKAAAAANIhoKSs2N7R4l2nghIAAACAlAgoKSu1eOftQQkAAABASiRRlJX3oNTiDQAAAEBKBJSUlfagNCQHAAAAgLQIKCkr7UEpoAQAAAAgLQJKytrKLd5uCwAAAADSIYmirFgsDclRQQkAAABAOgSUlLVp8QYAAAAgZQJKyopavAEAAABImSSKskK7Kd4AAAAApEtASVmh2NninRdQAgAAAJAOASVlRRWUAAAAAKRMQElZW3mKt9sCAAAAgHRIoigrVVDWafEGAAAAICUCSsoK7R17UOa1eAMAAACQEgElZYWiPSgBAAAASJeAkrJCeUiO2wIAAACAdEiiKCvtQZm3ByUAAAAAKRFQUtZW7NiDsk4FJQAAAAApkURRVq6gtAclAAAAACkRUFJW3oNSizcAAAAAKRFQUlZo72jxNsUbAAAAgLQIKCkrFk3xBgAAACBdkijK2rR4AwAAAJAyASVlpSE5WrwBAAAASIuAkrK2YscelKZ4AwAAAJAWASVlpQrKurzbAgAAAIB0SKIoK3QGlCooAQAAAEiLgJKyQmeLtz0oAQAAAEiLgJKIiGhvT6KzgDJqtXgDAAAAkBJJFBERUUyS8q+1eAMAAACQFgElERFRKG4NKOvyAkoAAAAA0iGgJCIiCu3t5V+roAQAAAAgLQJKIqJrBWVtjdsCAAAAgHRIooiIiELnhJxcTgUlAAAAAOkRUBIREcXOgLJWOAkAAABAigSUREREW7FjD0rt3QAAAACkSRpFRKigBAAAACAbAkoiYusU73xeQAkAAABAegSURMTWITlavAEAAABIkzSKiIgoFLV4AwAAAJA+ASURsbWCMi+gBAAAACBFAkoiIqLYuQdlnT0oAQAAAEiRgJKI2NrirYISAAAAgDQJKImIrS3edXm3BAAAAADpkUYREfagBAAAACAbAkoiIqJQ7NiD0hRvAAAAANIkoCQitlZQ1mrxBgAAACBF0igiIqKoxRsAAACADAgoiYiIts4W77q8gBIAAACA9AgoiYhtKyjdEgAAAACkRxpFREQUip17UGrxBgAAACBFAkoiYpshOQJKAAAAAFIkoCQiIortHXtQ1tqDEgAAAIAUCSiJiIi2oj0oAQAAAEifNIqI2Dokp06LNwAAAAApyjygvPrqq2PSpEkxdOjQmD59etx33319nn/TTTfFwQcfHMOHD4+xY8fGqaeeGuvXr+9yzq233hpTp06N+vr6mDp1atx2222V/Ai7hUJ5ireAEgAAAID0ZBpQLlmyJObPnx/nnntuLF++PGbPnh3HHXdcNDU19Xj+/fffHx//+MfjtNNOi8cffzy+//3vx69//es4/fTTy+c8+OCDMXfu3Jg3b148+uijMW/evPjwhz8cDz30UFofa5dUKJb2oMw8swYAAACgimSaRl1yySVx2mmnxemnnx5TpkyJSy+9NCZMmBCLFi3q8fxf/epXsd9++8VZZ50VkyZNiqOOOio+/elPxyOPPFI+59JLL42jjz46FixYEJMnT44FCxbEe9/73rj00ktT+lS7JlO8AQAAAMhCZgHlli1bYtmyZTFnzpwux+fMmRMPPPBAj++ZNWtWPPfcc3HHHXdEkiTx4osvxg9+8IM4/vjjy+c8+OCD3a55zDHH9HrNiIjNmzdHS0tLl1e1KXRO8dbiDQAAAECaMgso161bF8ViMcaMGdPl+JgxY2LNmjU9vmfWrFlx0003xdy5c2PIkCHR2NgYe+65Z1xxxRXlc9asWdOva0ZELFy4MBoaGsqvCRMm7MQn2zWVKijr8gJKAAAAANKT+YaDuVzXQCxJkm7HSlauXBlnnXVW/Nu//VssW7Ys7rrrrnjmmWfijDPO2OFrRkQsWLAgNmzYUH6tXr16Bz/NrqtYLA3JyfyWAAAAAKCK1Gb1jUePHh35fL5bZePatWu7VUCWLFy4MI488sj44he/GBERb3/722PEiBExe/bs+PKXvxxjx46NxsbGfl0zIqK+vj7q6+t38hPt2uxBCQAAAEAWMiuXGzJkSEyfPj2WLl3a5fjSpUtj1qxZPb7n1VdfjZq/qvDL5/MR0VElGRExc+bMbte8++67e70mHUp7UNZq8QYAAAAgRZlVUEZEnHPOOTFv3rw49NBDY+bMmXHNNddEU1NTuWV7wYIF8fzzz8eNN94YEREf+MAH4pOf/GQsWrQojjnmmGhubo758+fH4YcfHuPGjYuIiLPPPjve9a53xUUXXRQnnnhi/PjHP4577rkn7r///sw+566gUFRBCQAAAED6Mg0o586dG+vXr48LL7wwmpubY9q0aXHHHXfExIkTIyKiubk5mpqayuefcsop0draGldeeWV84QtfiD333DPe8573xEUXXVQ+Z9asWbF48eI477zz4vzzz483v/nNsWTJkpgxY0bqn29XUm7xztuDEgAAAID05JJSbzRlLS0t0dDQEBs2bIhRo0ZlvZxUfH7Jirht+fNx3vFT4vTZ+2e9HAAAAAB2Yf3J15TLERERbcWOPSjzWrwBAAAASJGAkoiIKGrxBgAAACAD0igiYps9KFVQAgAAAJAiASUREVHobPEWUAIAAACQJgElEbHtFG8BJQAAAADpEVASERGFYkdAma9xSwAAAACQHmkUEbF1SE6dFm8AAAAAUiSgJCIiCu0de1DmBZQAAAAApEhASUTYgxIAAACAbAgoiYite1DW2oMSAAAAgBRJo4iIrS3etVq8AQAAAEiRgJKI2LbF2y0BAAAAQHqkUUTE1inehuQAAAAAkCYBJRGx7R6UAkoAAAAA0iOgJCK22YPSFG8AAAAAUiSgJCK2tnib4g0AAABAmqRRREREW6nFWwUlAAAAACkSUBIR21ZQCigBAAAASI+AkoiIaCt27EFpijcAAAAAaRJQEhFbKyjr8m4JAAAAANIjjSKSJIlCZ0CpghIAAACANAkoKVdPRtiDEgAAAIB0CSgpV09GRNRq8QYAAAAgRdIougaUKigBAAAASJGAkigWBZQAAAAAZENASRTa28u/NiQHAAAAgDQJKOkywTuXE1ACAAAAkB4BJeWAUns3AAAAAGkTUFLeg1JACQAAAEDaBJREW+celLV5twMAAAAA6ZJIEUUt3gAAAABkREBJtBU7KihN8AYAAAAgbQJKyhWUdVq8AQAAAEiZRIryFG8VlAAAAACkTUBJFEzxBgAAACAjAkqiUJ7iLaAEAAAAIF0CSsoVlPkatwMAAAAA6ZJIsc2QHBWUAAAAAKRLQIkhOQAAAABkRkBJFIqde1AKKAEAAABImYCScgVlrT0oAQAAAEiZRIryHpSmeAMAAACQNgEl0abFGwAAAICMCCgpV1DmtXgDAAAAkDKJFNFW3oNSBSUAAAAA6RJQEsVSi7c9KAEAAABImYCSbaZ4CygBAAAASJeAknJAaQ9KAAAAANImkaI8JKdOizcAAAAAKRNQEm2de1DmtXgDAAAAkDIBJdtUULodAAAAAEiXRIpt9qBUQQkAAABAugSURKGzxdsUbwAAAADSJqCkXEFZa0gOAAAAACkTUFLegzJf43YAAAAAIF0SKaKt2DkkR4s3AAAAACkTUBLF9o49KPNavAEAAABImYCSKHRWUBqSAwAAAEDaBJRsHZJjD0oAAAAAUiaRojwkxxRvAAAAANImoCTaip17UGrxBgAAACBlAkrKFZR1WrwBAAAASJlEimjrDChVUAIAAACQNgElUWzvaPG2ByUAAAAAaRNQEoWiKd4AAAAAZEMiRRS0eAMAAACQEQEl5YCyTos3AAAAACkTUFLeg1IFJQAAAABpE1BS3oOyLu92AAAAACBdEinsQQkAAABAZgSURKHY0eJdK6AEAAAAIGUCSsoVlLVavAEAAABImUSKKJYCShWUAAAAAKRMQEm0Fe1BCQAAAEA2BJREsb1jD8q6vIASAAAAgHQJKIlCuYLS7QAAAABAuiRSbB2So8UbAAAAgJQJKNk6JEeLNwAAAAApE1ASbZ17UBqSAwAAAEDaBJRVrr09iaSjgDLq7EEJAAAAQMokUlWutP9kREReizcAAAAAKRNQVrlCZ3t3hCE5AAAAAKRPQFnltq2grNXiDQAAAEDKJFJVrlDcNqBUQQkAAABAugSUVa7U4l2Ti6gRUAIAAACQMgFllSt2tnhr7wYAAAAgC1KpKldq8c6rngQAAAAgAwLKKlcaklObF1ACAAAAkD4BZZUrFDv2oDQgBwAAAIAsCCir3NYKSrcCAAAAAOmTSlW5rUNyVFACAAAAkD4BZZVr62zxNiQHAAAAgCwIKKtcqYKyTos3AAAAABmQSlW50h6UKigBAAAAyIKAssoVivagBAAAACA7AsoqV2jv2IOyNi+gBAAAACB9AsoqV6qgzNe4FQAAAABIn1SqypX2oKzT4g0AAABABgSUVa5oSA4AAAAAGRJQVjl7UAIAAACQJQFllds6xdutAAAAAED6pFJVrlxBqcUbAAAAgAwIKKtcaUiOFm8AAAAAsiCgrHKlITlavAEAAADIglSqyrUVTfEGAAAAIDsCyipXNMUbAAAAgAwJKKtceQ9KFZQAAAAAZEBAWeUK5RZvtwIAAAAA6ZNKVblSBWWdFm8AAAAAMiCgrHKFYscelIbkAAAAAJAFAWWVK5YrKN0KAAAAAKRPKlXlSi3eKigBAAAAyIKAssqVWrxN8QYAAAAgCwLKKleqoKw1xRsAAACADEilqlyh2BlQmuINAAAAQAYElFVuawWlgBIAAACA9Akoq1yxvWMPSkNyAAAAAMiCgLLKtamgBAAAACBDAsoqVyzvQelWAAAAACB9UqkqZw9KAAAAALIkoKxyBXtQAgAAAJAhAWWVK3ZWUNZp8QYAAAAgA1KpKtdWVEEJAAAAQHYElFVuawWlgBIAAACA9Akoq1xpSE6+xq0AAAAAQPqkUlWuUDTFGwAAAIDsCCirXKmCslaLNwAAAAAZEFBWuYIhOQAAAABkSEBZ5bYOyXErAAAAAJA+qVSV2zokRwUlAAAAAOkTUFa5Uou3ITkAAAAAZEFAWeXKQ3Jq3AoAAAAApE8qVeWKpngDAAAAkCEBZZVrM8UbAAAAgAwJKKtceYq3Fm8AAAAAMiCVqnJtpSneWrwBAAAAyICAssptraAUUAIAAACQPgFlFUuSpBxQ2oMSAAAAgCwIKKtYoTOcjIiotQclAAAAABmQSlWx4rYBpT0oAQAAAMiAgLKKtRXby7/W4g0AAABAFjIPKK+++uqYNGlSDB06NKZPnx733Xdfr+eecsopkcvlur0OOuig8jk33HBDj+ds2rQpjY+zS9m2grIun/mtAAAAAEAVyjSVWrJkScyfPz/OPffcWL58ecyePTuOO+64aGpq6vH8yy67LJqbm8uv1atXx9577x0f+tCHupw3atSoLuc1NzfH0KFD0/hIu5Rt96BUQAkAAABAFjINKC+55JI47bTT4vTTT48pU6bEpZdeGhMmTIhFixb1eH5DQ0M0NjaWX4888ki89NJLceqpp3Y5L5fLdTmvsbExjY+zyykUOwLK2pqOKlMAAAAASFtmAeWWLVti2bJlMWfOnC7H58yZEw888MB2XePb3/52vO9974uJEyd2Ob5x48aYOHFijB8/Pk444YRYvnx5n9fZvHlztLS0dHlVg0J7xx6UBuQAAAAAkJXMAsp169ZFsViMMWPGdDk+ZsyYWLNmzeu+v7m5Oe688844/fTTuxyfPHly3HDDDXH77bfHzTffHEOHDo0jjzwynnrqqV6vtXDhwmhoaCi/JkyYsGMfahdT2oOytsb+kwAAAABkI/Nk6q9bi5Mk2a524xtuuCH23HPPOOmkk7ocP+KII+Lkk0+Ogw8+OGbPnh233HJLvPWtb40rrrii12stWLAgNmzYUH6tXr16hz7Lrqats8XbBG8AAAAAslKb1TcePXp05PP5btWSa9eu7VZV+deSJInrrrsu5s2bF0OGDOnz3JqamjjssMP6rKCsr6+P+vr67V/8bqJUQVmnxRsAAACAjGRWQTlkyJCYPn16LF26tMvxpUuXxqxZs/p877333htPP/10nHbaaa/7fZIkiRUrVsTYsWN3ar27o7Zixx6UKigBAAAAyEpmFZQREeecc07MmzcvDj300Jg5c2Zcc8010dTUFGeccUZEdLReP//883HjjTd2ed+3v/3tmDFjRkybNq3bNS+44II44ogj4oADDoiWlpa4/PLLY8WKFXHVVVel8pl2JfagBAAAACBrmQaUc+fOjfXr18eFF14Yzc3NMW3atLjjjjvKU7mbm5ujqampy3s2bNgQt956a1x22WU9XvPll1+OT33qU7FmzZpoaGiIQw45JH75y1/G4YcfXvHPs6splAJKLd4AAAAAZCSXJEmS9SIGm5aWlmhoaIgNGzbEqFGjsl5OxTz0x/Ux95pfxf5vGBE//8LfZr0cAAAAAHYT/cnX9PZWsfKQHC3eAAAAAGREMlXF2joDSkNyAAAAAMiKgLKKFds7pnjX2YMSAAAAgIwIKKtYoaiCEgAAAIBsCSirWHmKtz0oAQAAAMiIZKqKlQNKLd4AAAAAZERAWcVKe1Bq8QYAAAAgKwLKKtZWLLV4CygBAAAAyIaAsooVyy3ebgMAAAAAsiGZqmKFYkeLtwpKAAAAALIioKxiBRWUAAAAAGRMMlXFyi3eKigBAAAAyIiAsoqVhuSY4g0AAABAVgSUVazY3rEHZV1eQAkAAABANgSUVUwFJQAAAABZE1BWsa17ULoNAAAAAMiGZKqKFQzJAQAAACBjAsoqVih27EGZtwclAAAAABkRUFaxUgVlnRZvAAAAADIimapipT0oDckBAAAAICsCyipWaO9o8bYHJQAAAABZEVBWsUKxc0hO3m0AAAAAQDYkU1XMFG8AAAAAsiagrGLlgNIUbwAAAAAyIqCsYkV7UAIAAACQMQFlFWsrlqZ4uw0AAAAAyIZkqooVtXgDAAAAkDEBZRVrK2rxBgAAACBbAsoqVqqgzAsoAQAAAMiIgLKKlaZ41+XdBgAAAABkQzJVxQqdLd4qKAEAAADIioCyihXLFZQCSgAAAACyIaCsYoXyHpRuAwAAAACyIZmqYoViR0BpijcAAAAAWRFQVrFCe8celAJKAAAAALIioKxipRbvWntQAgAAAJARAWUV29ri7TYAAAAAIBuSqSpWLA/JUUEJAAAAQDYElFWsvAelFm8AAAAAMiKgrGLlPSi1eAMAAACQEclUFdu6B6UKSgAAAACyIaCsYqUWb3tQAgAAAJAVAWUVKw3Jqcu7DQAAAADIhmSqSiVJEm1FU7wBAAAAyJaAskp1Fk9GRESdKd4AAAAAZERAWaVK+09GqKAEAAAAIDsCyipVmuAdEVFb4zYAAAAAIBuSqSpV2KbHu1aLNwAAAAAZEVBWqUJxa4t3rRZvAAAAADIioKxSxfatE7xzOQElAAAAANkQUFapwjYBJQAAAABkRUBZpUpDcrR3AwAAAJAlAWWVKrR37EEpoAQAAAAgSwLKKlVq8a7NuwUAAAAAyI50qkqVWrztQQkAAABAlgSUVao0xbtOQAkAAABAhgSUVaqtcw/KfF5ACQAAAEB2BJRVamsFpVsAAAAAgOxIp6qUPSgBAAAAGAwElFWqUGrxFlACAAAAkCEBZZUqlFq8824BAAAAALIjnapSWrwBAAAAGAwElFWq2NniXWeKNwAAAAAZElBWqVKLtwpKAAAAALIkoKxSpRbv2hq3AAAAAADZkU5VqVIFZa0WbwAAAAAyJKCsUoVixx6UtVq8AQAAAMiQgLJK2YMSAAAAgMFAQFmliuUWb7cAAAAAANmRTlWpNi3eAAAAAAwCAsoqVa6gNMUbAAAAgAxJp6pUeYq3CkoAAAAAMiSgrFKFYueQnLyAEgAAAIDsCCirVLG9Yw/KOhWUAAAAAGRIQFml2jpbvPP2oAQAAAAgQ9KpKlUaklOnxRsAAACADAkoq1R5D0ot3gAAAABkSEBZpQqde1Ca4g0AAABAlgSUVarQ2eJdm3cLAAAAAJAd6VSVKhQ7Kii1eAMAAACQJQFllSpXUAooAQAAAMiQgLJKFbV4AwAAADAISKeqVGmKtwpKAAAAALIkoKxS5SneeQElAAAAANkRUFapoj0oAQAAABgEBJRVqq2zxTtf4xYAAAAAIDvSqSpVqqCs0+INAAAAQIYElFWqrdixB2VeizcAAAAAGRJQVil7UAIAAAAwGAgoq1ShHFC6BQAAAADIjnSqShXaO1u87UEJAAAAQIYElFWq0DnFu04FJQAAAAAZkk5VqVKLtyE5AAAAAGRJQFmlykNytHgDAAAAkCEBZZUq7UFpijcAAAAAWRJQVqnSHpSmeAMAAACQJelUlSpo8QYAAABgEBBQVqnyHpRavAEAAADIkICySrUVO/agNMUbAAAAgCwJKKtUqYKyLu8WAAAAACA70qkqVRqSo4ISAAAAgCwJKKtUob2jxdselAAAAABkSUBZhdrbk+js8I5aLd4AAAAAZEg6VYUKpXQytHgDAAAAkC0BZRUqbhNQ1uUFlAAAAABkR0BZhdo695+MUEEJAAAAQLYElFWoWNxaQVlb4xYAAAAAIDvSqSpU2oMyl1NBCQAAAEC2BJRVqNDZ4l0rnAQAAAAgYwLKKlTobPHW3g0AAABA1iRUVag0xVsFJQAAAABZE1BWoVKLdz4voAQAAAAgWwLKKlRo1+INAAAAwOAgoapCW/egVEEJAAAAQLYElFWoVEGZF1ACAAAAkDEBZRUqdu5BWWcPSgAAAAAyJqCsQm1FFZQAAAAADA4CyipU7Gzxrsv7xw8AAABAtiRUVait2NHirYISAAAAgKwJKKtQqYLSFG8AAAAAsiagrEKlKd61WrwBAAAAyJiEqgoVDMkBAAAAYJAQUFahQnvHHpR1eQElAAAAANkSUFah0h6U+Rr/+AEAAADIloSqCpVavA3JAQAAACBrAsoqVDDFGwAAAIBBQkBZhUbvMSQO22+vOGDMHlkvBQAAAIAqV5v1AkjfnIMaY85BjVkvAwAAAABUUAIAAAAA2RFQAgAAAACZEVACAAAAAJkRUAIAAAAAmRFQAgAAAACZEVACAAAAAJkRUAIAAAAAmRFQAgAAAACZEVACAAAAAJkRUAIAAAAAmRFQAgAAAACZEVACAAAAAJnJPKC8+uqrY9KkSTF06NCYPn163Hfffb2ee8opp0Qul+v2Ouigg7qcd+utt8bUqVOjvr4+pk6dGrfddlulPwYAAAAAsAMyDSiXLFkS8+fPj3PPPTeWL18es2fPjuOOOy6ampp6PP+yyy6L5ubm8mv16tWx9957x4c+9KHyOQ8++GDMnTs35s2bF48++mjMmzcvPvzhD8dDDz2U1scCAAAAALZTLkmSJKtvPmPGjHjnO98ZixYtKh+bMmVKnHTSSbFw4cLXff+PfvSj+Pu///t45plnYuLEiRERMXfu3GhpaYk777yzfN6xxx4be+21V9x8883bta6WlpZoaGiIDRs2xKhRo/r5qQAAAACguvUnX8usgnLLli2xbNmymDNnTpfjc+bMiQceeGC7rvHtb3873ve+95XDyYiOCsq/vuYxxxyz3dcEAAAAANJTm9U3XrduXRSLxRgzZkyX42PGjIk1a9a87vubm5vjzjvvjO9973tdjq9Zs6bf19y8eXNs3ry5/PuWlpbt+QgAAAAAwE7KfEhOLpfr8vskSbod68kNN9wQe+65Z5x00kk7fc2FCxdGQ0ND+TVhwoTtWzwAAAAAsFMyCyhHjx4d+Xy+W2Xj2rVru1VA/rUkSeK6666LefPmxZAhQ7p8rbGxsd/XXLBgQWzYsKH8Wr16dT8/DQAAAACwIzILKIcMGRLTp0+PpUuXdjm+dOnSmDVrVp/vvffee+Ppp5+O0047rdvXZs6c2e2ad999d5/XrK+vj1GjRnV5AQAAAACVl9kelBER55xzTsybNy8OPfTQmDlzZlxzzTXR1NQUZ5xxRkR0VDY+//zzceONN3Z537e//e2YMWNGTJs2rds1zz777HjXu94VF110UZx44onx4x//OO655564//77U/lMAAAAAMD2yzSgnDt3bqxfvz4uvPDCaG5ujmnTpsUdd9xRnsrd3NwcTU1NXd6zYcOGuPXWW+Oyyy7r8ZqzZs2KxYsXx3nnnRfnn39+vPnNb44lS5bEjBkzKv55AAAAAID+ySVJkmS9iMGmpaUlGhoaYsOGDdq9AQAAAKCf+pOvZT7FGwAAAACoXgJKAAAAACAzAkoAAAAAIDMCSgAAAAAgMwJKAAAAACAzAkoAAAAAIDMCSgAAAAAgMwJKAAAAACAzAkoAAAAAIDMCSgAAAAAgMwJKAAAAACAzAkoAAAAAIDMCSgAAAAAgMwJKAAAAACAzAkoAAAAAIDMCSgAAAAAgM7VZL2AwSpIkIiJaWloyXgkAAAAA7HpKuVopZ+uLgLIHra2tERExYcKEjFcCAAAAALuu1tbWaGho6POcXLI9MWaVaW9vjxdeeCFGjhwZuVwu6+Vst5aWlpgwYUKsXr06Ro0alfVyoCp47iB9njvIhmcP0ue5g/R57gZOkiTR2toa48aNi5qavneZVEHZg5qamhg/fnzWy9hho0aN8hBByjx3kD7PHWTDswfp89xB+jx3A+P1KidLDMkBAAAAADIjoAQAAAAAMiOg3I3U19fHl770paivr896KVA1PHeQPs8dZMOzB+nz3EH6PHfZMCQHAAAAAMiMCkoAAAAAIDMCSgAAAAAgMwJKAAAAACAzAkoAAAAAIDMCyt3E1VdfHZMmTYqhQ4fG9OnT47777st6SbDLWrhwYRx22GExcuTI2HfffeOkk06KJ554oss5SZLEv//7v8e4ceNi2LBh8bd/+7fx+OOPdzln8+bN8bnPfS5Gjx4dI0aMiA9+8IPx3HPPpflRYJe1cOHCyOVyMX/+/PIxzx0MvOeffz5OPvnk2GeffWL48OHxjne8I5YtW1b+uucOBl6hUIjzzjsvJk2aFMOGDYv9998/Lrzwwmhvby+f49mDnfPLX/4yPvCBD8S4ceMil8vFj370oy5fH6hn7KWXXop58+ZFQ0NDNDQ0xLx58+Lll1+u8KfbPQkodwNLliyJ+fPnx7nnnhvLly+P2bNnx3HHHRdNTU1ZLw12Sffee2+ceeaZ8atf/SqWLl0ahUIh5syZE6+88kr5nK997WtxySWXxJVXXhm//vWvo7GxMY4++uhobW0tnzN//vy47bbbYvHixXH//ffHxo0b44QTTohisZjFx4Jdxq9//eu45ppr4u1vf3uX4547GFgvvfRSHHnkkVFXVxd33nlnrFy5Mi6++OLYc889y+d47mDgXXTRRfHNb34zrrzyyli1alV87Wtfi69//etxxRVXlM/x7MHOeeWVV+Lggw+OK6+8ssevD9Qz9r//9/+OFStWxF133RV33XVXrFixIubNm1fxz7dbStjlHX744ckZZ5zR5djkyZOTf/mXf8loRbB7Wbt2bRIRyb333pskSZK0t7cnjY2NyVe/+tXyOZs2bUoaGhqSb37zm0mSJMnLL7+c1NXVJYsXLy6f8/zzzyc1NTXJXXfdle4HgF1Ia2trcsABByRLly5N/uZv/iY5++yzkyTx3EEl/PM//3Ny1FFH9fp1zx1UxvHHH5/84z/+Y5djf//3f5+cfPLJSZJ49mCgRURy2223lX8/UM/YypUrk4hIfvWrX5XPefDBB5OISH7/+99X+FPtflRQ7uK2bNkSy5Ytizlz5nQ5PmfOnHjggQcyWhXsXjZs2BAREXvvvXdERDzzzDOxZs2aLs9dfX19/M3f/E35uVu2bFm0tbV1OWfcuHExbdo0zyb04cwzz4zjjz8+3ve+93U57rmDgXf77bfHoYceGh/60Idi3333jUMOOSS+9a1vlb/uuYPKOOqoo+JnP/tZPPnkkxER8eijj8b9998f73//+yPCsweVNlDP2IMPPhgNDQ0xY8aM8jlHHHFENDQ0eA53QG3WC2DnrFu3LorFYowZM6bL8TFjxsSaNWsyWhXsPpIkiXPOOSeOOuqomDZtWkRE+dnq6bl79tlny+cMGTIk9tprr27neDahZ4sXL45ly5bFI4880u1rnjsYeH/84x9j0aJFcc4558S//uu/xsMPPxxnnXVW1NfXx8c//nHPHVTIP//zP8eGDRti8uTJkc/no1gsxn/8x3/ERz/60Yjwdx5U2kA9Y2vWrIl999232/X33Xdfz+EOEFDuJnK5XJffJ0nS7RjQf5/97Gfjt7/9bdx///3dvrYjz51nE3q2evXqOPvss+Puu++OoUOH9nqe5w4GTnt7exx66KHxla98JSIiDjnkkHj88cdj0aJF8fGPf7x8nucOBtaSJUviu9/9bnzve9+Lgw46KFasWBHz58+PcePGxSc+8YnyeZ49qKyBeMZ6Ot9zuGO0eO/iRo8eHfl8vls6v3bt2m7/bwDQP5/73Ofi9ttvj1/84hcxfvz48vHGxsaIiD6fu8bGxtiyZUu89NJLvZ4DbLVs2bJYu3ZtTJ8+PWpra6O2tjbuvffeuPzyy6O2trb83HjuYOCMHTs2pk6d2uXYlClTyoMW/X0HlfHFL34x/uVf/iU+8pGPxNve9raYN29efP7zn4+FCxdGhGcPKm2gnrHGxsZ48cUXu13/z3/+s+dwBwgod3FDhgyJ6dOnx9KlS7scX7p0acyaNSujVcGuLUmS+OxnPxs//OEP4+c//3lMmjSpy9cnTZoUjY2NXZ67LVu2xL333lt+7qZPnx51dXVdzmlubo7f/e53nk3owXvf+9547LHHYsWKFeXXoYceGh/72MdixYoVsf/++3vuYIAdeeSR8cQTT3Q59uSTT8bEiRMjwt93UCmvvvpq1NR0/U/xfD4f7e3tEeHZg0obqGds5syZsWHDhnj44YfL5zz00EOxYcMGz+GOyGIyDwNr8eLFSV1dXfLtb387WblyZTJ//vxkxIgRyZ/+9Keslwa7pM985jNJQ0ND8j//8z9Jc3Nz+fXqq6+Wz/nqV7+aNDQ0JD/84Q+Txx57LPnoRz+ajB07NmlpaSmfc8YZZyTjx49P7rnnnuQ3v/lN8p73vCc5+OCDk0KhkMXHgl3OtlO8k8RzBwPt4YcfTmpra5P/+I//SJ566qnkpptuSoYPH55897vfLZ/juYOB94lPfCJ54xvfmPz3f/938swzzyQ//OEPk9GjRyf/5//8n/I5nj3YOa2trcny5cuT5cuXJxGRXHLJJcny5cuTZ599NkmSgXvGjj322OTtb3978uCDDyYPPvhg8ra3vS054YQTUv+8uwMB5W7iqquuSiZOnJgMGTIkeec735nce++9WS8JdlkR0ePr+uuvL5/T3t6efOlLX0oaGxuT+vr65F3velfy2GOPdbnOa6+9lnz2s59N9t5772TYsGHJCSeckDQ1NaX8aWDX9dcBpecOBt5PfvKTZNq0aUl9fX0yefLk5Jprrunydc8dDLyWlpbk7LPPTt70pjclQ4cOTfbff//k3HPPTTZv3lw+x7MHO+cXv/hFj/9N94lPfCJJkoF7xtavX5987GMfS0aOHJmMHDky+djHPpa89NJLKX3K3UsuSZIkm9pNAAAAAKDa2YMSAAAAAMiMgBIAAAAAyIyAEgAAAADIjIASAAAAAMiMgBIAAAAAyIyAEgAAAADIjIASAAAAAMiMgBIAgN3afvvtF5deemnWywAAoBcCSgAAMnHKKadELpeLXC4XtbW18aY3vSk+85nPxEsvvZT10gAASJGAEgCAzBx77LHR3Nwcf/rTn+Laa6+Nn/zkJ/FP//RPWS8LAIAUCSgBAMhMfX19NDY2xvjx42POnDkxd+7cuPvuuyMiolgsxmmnnRaTJk2KYcOGxYEHHhiXXXZZl/efcsopcdJJJ8U3vvGNGDt2bOyzzz5x5plnRltbW6/f8/rrr4+GhoZYunRpRT8bAADbpzbrBQAAQETEH//4x7jrrruirq4uIiLa29tj/Pjxccstt8To0aPjgQceiE996lMxduzY+PCHP1x+3y9+8YsYO3Zs/OIXv4inn3465s6dG+94xzvik5/8ZLfv8Y1vfCMWLlwYP/3pT+OII45I7bMBANA7ASUAAJn57//+79hjjz2iWCzGpk2bIiLikksuiYiIurq6uOCCC8rnTpo0KR544IG45ZZbugSUe+21V1x55ZWRz+dj8uTJcfzxx8fPfvazbgHlggUL4jvf+U78z//8T7ztbW9L4dMBALA9BJQAAGTm3e9+dyxatCheffXVuPbaa+PJJ5+Mz33uc+Wvf/Ob34xrr702nn322Xjttddiy5Yt8Y53vKPLNQ466KDI5/Pl348dOzYee+yxLudcfPHF8corr8QjjzwS+++/f0U/EwAA/WMPSgAAMjNixIh4y1veEm9/+9vj8ssvj82bN5erJm+55Zb4/Oc/H//4j/8Yd999d6xYsSJOPfXU2LJlS5drlFrCS3K5XLS3t3c5Nnv27CgWi3HLLbdU9gMBANBvKigBABg0vvSlL8Vxxx0Xn/nMZ+K+++6LWbNmdZnq/Yc//GGHrnv44YfH5z73uTjmmGMin8/HF7/4xYFaMgAAO0lACQDAoPG3f/u3cdBBB8VXvvKVOOCAA+LGG2+Mn/70pzFp0qT4r//6r/j1r38dkyZN2qFrz5w5M+6888449thjo7a2Nj7/+c8P8OoBANgRAkoAAAaVc845J0499dR48sknY8WKFTF37tzI5XLx0Y9+NP7pn/4p7rzzzh2+9pFHHhn/7//9v3j/+98f+Xw+zjrrrAFcOQAAOyKXJEmS9SIAAAAAgOpkSA4AAAAAkBkBJQAAAACQGQElAAAAAJAZASUAAAAAkBkBJQAAAACQGQElAAAAAJAZASUAAAAAkBkBJQAAAACQGQElAAAAAJAZASUAAAAAkBkBJQAAAACQGQElAAAAAJCZ/x8eJt8uq+xJDAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1600x1200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,12))\n",
    "custom_ticks = [10, 20, 50, 100, 200, 1024]\n",
    "plt.plot(custom_ticks,l)\n",
    "plt.xlabel(\"Rank\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d069276",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9d478f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVDNetwork = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "94d17ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_initializer(u, s, v):\n",
    "    def initialize_weights(shape, dtype=None):\n",
    "        return tf.matmul(u, tf.matmul(tf.linalg.diag(s), tf.transpose(v)))\n",
    "    return initialize_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2a0478b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_svd(layer, k, j):\n",
    "    weights, biases = weight_matrix[j], bias_matrix[j]\n",
    "    u, s, v = np.linalg.svd(weights)\n",
    "    u = u[:, :k]\n",
    "    s = s[:k]\n",
    "    v = v[:, :k]\n",
    "    v = np.matmul(np.diag(s[:20]), v[:, :20].T) # Transpose V_D\n",
    "    custom_weights_initializer = custom_initializer(u, s, v)\n",
    "    SVDNetwork.add(tf.keras.layers.Dense(20,use_bias = False, weights = [u]))\n",
    "    SVDNetwork.add(tf.keras.layers.Dense(1024, activation='relu', weights = [v,biases]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "db171dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(Baseline.layers) - 1):\n",
    "    apply_svd(Baseline.layers[i],20, i-1)\n",
    "    layer = SVDNetwork.layers[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4368a444",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVDNetwork.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "32840fba",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_12 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 20)                15680     \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 1024)              21504     \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 20)                20480     \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 1024)              21504     \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 20)                20480     \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 1024)              21504     \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 20)                20480     \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 1024)              21504     \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 20)                20480     \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 1024)              21504     \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 10)                10250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 215,370\n",
      "Trainable params: 215,370\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "SVDNetwork.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "80494fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "metrics = [\"accuracy\"]\n",
    "SVDNetwork.compile(loss=loss, optimizer=opt, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "88e824b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "120/120 [==============================] - 5s 26ms/step - loss: 257.3396 - accuracy: 0.1023 - val_loss: 2.4309 - val_accuracy: 0.0952\n",
      "Epoch 2/50\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 2.3094 - accuracy: 0.1201 - val_loss: 2.2655 - val_accuracy: 0.1030\n",
      "Epoch 3/50\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 2.1940 - accuracy: 0.1992 - val_loss: 2.0427 - val_accuracy: 0.3848\n",
      "Epoch 4/50\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 1.8237 - accuracy: 0.3758 - val_loss: 1.4814 - val_accuracy: 0.4670\n",
      "Epoch 5/50\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 1.3195 - accuracy: 0.5342 - val_loss: 1.1307 - val_accuracy: 0.6121\n",
      "Epoch 6/50\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.9577 - accuracy: 0.6896 - val_loss: 0.7416 - val_accuracy: 0.7868\n",
      "Epoch 7/50\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.6535 - accuracy: 0.8029 - val_loss: 0.5504 - val_accuracy: 0.8433\n",
      "Epoch 8/50\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.5020 - accuracy: 0.8531 - val_loss: 0.4423 - val_accuracy: 0.8739\n",
      "Epoch 9/50\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 0.4294 - accuracy: 0.8736 - val_loss: 0.4066 - val_accuracy: 0.8793\n",
      "Epoch 10/50\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.3704 - accuracy: 0.8919 - val_loss: 0.3352 - val_accuracy: 0.9032\n",
      "Epoch 11/50\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.3232 - accuracy: 0.9079 - val_loss: 0.3041 - val_accuracy: 0.9099\n",
      "Epoch 12/50\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.2935 - accuracy: 0.9150 - val_loss: 0.2857 - val_accuracy: 0.9145\n",
      "Epoch 13/50\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 0.2645 - accuracy: 0.9240 - val_loss: 0.2507 - val_accuracy: 0.9285\n",
      "Epoch 14/50\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 0.2448 - accuracy: 0.9297 - val_loss: 0.2414 - val_accuracy: 0.9301\n",
      "Epoch 15/50\n",
      "120/120 [==============================] - 3s 28ms/step - loss: 0.2264 - accuracy: 0.9351 - val_loss: 0.2348 - val_accuracy: 0.9311\n",
      "Epoch 16/50\n",
      "120/120 [==============================] - 3s 27ms/step - loss: 0.2114 - accuracy: 0.9391 - val_loss: 0.2216 - val_accuracy: 0.9335\n",
      "Epoch 17/50\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 0.2019 - accuracy: 0.9423 - val_loss: 0.2020 - val_accuracy: 0.9447\n",
      "Epoch 18/50\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 0.1933 - accuracy: 0.9441 - val_loss: 0.1964 - val_accuracy: 0.9438\n",
      "Epoch 19/50\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 0.1781 - accuracy: 0.9489 - val_loss: 0.1912 - val_accuracy: 0.9427\n",
      "Epoch 20/50\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.1658 - accuracy: 0.9513 - val_loss: 0.1815 - val_accuracy: 0.9478\n",
      "Epoch 21/50\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.1640 - accuracy: 0.9518 - val_loss: 0.1768 - val_accuracy: 0.9498\n",
      "Epoch 22/50\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.1566 - accuracy: 0.9537 - val_loss: 0.1737 - val_accuracy: 0.9480\n",
      "Epoch 23/50\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 0.1461 - accuracy: 0.9569 - val_loss: 0.1624 - val_accuracy: 0.9546\n",
      "Epoch 24/50\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 0.1439 - accuracy: 0.9576 - val_loss: 0.1730 - val_accuracy: 0.9517\n",
      "Epoch 25/50\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 0.1423 - accuracy: 0.9588 - val_loss: 0.1739 - val_accuracy: 0.9522\n",
      "Epoch 26/50\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.1359 - accuracy: 0.9597 - val_loss: 0.1883 - val_accuracy: 0.9472\n",
      "Epoch 27/50\n",
      "120/120 [==============================] - 3s 27ms/step - loss: 0.1373 - accuracy: 0.9603 - val_loss: 0.1679 - val_accuracy: 0.9515\n",
      "Epoch 28/50\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 0.1345 - accuracy: 0.9604 - val_loss: 0.1464 - val_accuracy: 0.9593\n",
      "Epoch 29/50\n",
      "120/120 [==============================] - 3s 28ms/step - loss: 0.1297 - accuracy: 0.9621 - val_loss: 0.1401 - val_accuracy: 0.9589\n",
      "Epoch 30/50\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.1158 - accuracy: 0.9654 - val_loss: 0.1545 - val_accuracy: 0.9572\n",
      "Epoch 31/50\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.1221 - accuracy: 0.9637 - val_loss: 0.1399 - val_accuracy: 0.9608\n",
      "Epoch 32/50\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.1178 - accuracy: 0.9651 - val_loss: 0.1390 - val_accuracy: 0.9609\n",
      "Epoch 33/50\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.1162 - accuracy: 0.9664 - val_loss: 0.1326 - val_accuracy: 0.9626\n",
      "Epoch 34/50\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 0.1127 - accuracy: 0.9661 - val_loss: 0.1714 - val_accuracy: 0.9537\n",
      "Epoch 35/50\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.1074 - accuracy: 0.9686 - val_loss: 0.1645 - val_accuracy: 0.9551\n",
      "Epoch 36/50\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.1048 - accuracy: 0.9694 - val_loss: 0.1469 - val_accuracy: 0.9606\n",
      "Epoch 37/50\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.1009 - accuracy: 0.9697 - val_loss: 0.1331 - val_accuracy: 0.9608\n",
      "Epoch 38/50\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.1009 - accuracy: 0.9704 - val_loss: 0.1326 - val_accuracy: 0.9628\n",
      "Epoch 39/50\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.0906 - accuracy: 0.9736 - val_loss: 0.1387 - val_accuracy: 0.9619\n",
      "Epoch 40/50\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.0911 - accuracy: 0.9727 - val_loss: 0.1382 - val_accuracy: 0.9643\n",
      "Epoch 41/50\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.0838 - accuracy: 0.9746 - val_loss: 0.1305 - val_accuracy: 0.9649\n",
      "Epoch 42/50\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.0863 - accuracy: 0.9737 - val_loss: 0.1325 - val_accuracy: 0.9638\n",
      "Epoch 43/50\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.0841 - accuracy: 0.9747 - val_loss: 0.1240 - val_accuracy: 0.9673\n",
      "Epoch 44/50\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 0.0862 - accuracy: 0.9743 - val_loss: 0.1380 - val_accuracy: 0.9655\n",
      "Epoch 45/50\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.0785 - accuracy: 0.9765 - val_loss: 0.1282 - val_accuracy: 0.9650\n",
      "Epoch 46/50\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.0729 - accuracy: 0.9782 - val_loss: 0.1330 - val_accuracy: 0.9649\n",
      "Epoch 47/50\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.0756 - accuracy: 0.9780 - val_loss: 0.1286 - val_accuracy: 0.9672\n",
      "Epoch 48/50\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.0745 - accuracy: 0.9776 - val_loss: 0.1186 - val_accuracy: 0.9695\n",
      "Epoch 49/50\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.0652 - accuracy: 0.9806 - val_loss: 0.1242 - val_accuracy: 0.9687\n",
      "Epoch 50/50\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.0655 - accuracy: 0.9803 - val_loss: 0.1175 - val_accuracy: 0.9694\n"
     ]
    }
   ],
   "source": [
    "SVDNetwork_history=SVDNetwork.fit(x_train, y_train, batch_size=500, epochs=50, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c7968fea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(15,15))\n",
    "plt.plot(SVDNetwork_history.history[\"val_accuracy\"],label = \"SVD Network\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da244951",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "428f2481",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.custom_gradient\n",
    "def weight_update(w):\n",
    "    s,u,v=tf.linalg.svd(w,compute_uv=True,full_matrices=True)\n",
    "    u = u[:, :20]\n",
    "    s = s[:20]\n",
    "    v = v[:, :20]\n",
    "    wt = tf.matmul(u, tf.matmul(tf.linalg.diag(s), tf.transpose(v)))\n",
    "    def grad_temp(dy):\n",
    "        return dy\n",
    "    return wt, grad_temp\n",
    "\n",
    "class CustSVDLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,units,weights):\n",
    "      super(CustSVDLayer, self).__init__()\n",
    "      self.units=units\n",
    "      self.activation=tf.keras.activations.get(\"relu\")\n",
    "      self.w=tf.Variable(\n",
    "            initial_value=weights[0],\n",
    "            trainable=True,\n",
    "        )\n",
    "      self.b=tf.Variable(\n",
    "            initial_value=weights[1],\n",
    "            trainable=True,\n",
    "        )\n",
    "    def call(self, inputs):\n",
    "        w1=weight_update(self.w)  \n",
    "        a=self.activation(tf.matmul(inputs,w1)+self.b)\n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cac3f45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3=tf.keras.Sequential(\n",
    "    [     tf.keras.layers.Flatten(input_shape=(28,28,1)),\n",
    "     CustSVDLayer(units=1024,weights=[weight_matrix[0],bias_matrix[0]]),\n",
    "     CustSVDLayer(units=1024,weights=[weight_matrix[1],bias_matrix[1]]),\n",
    "     CustSVDLayer(units=1024,weights=[weight_matrix[2],bias_matrix[2]]),\n",
    "     CustSVDLayer(units=1024,weights=[weight_matrix[3],bias_matrix[3]]),\n",
    "     CustSVDLayer(units=1024,weights=[weight_matrix[4],bias_matrix[4]]),\n",
    "     tf.keras.layers.Dense(units=10,input_shape=(1024,),activation='softmax',name='last_layer',weights=[w_matrix[5],b_matrix[5]])\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed7ca8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 388s 825ms/step - loss: 0.0215 - accuracy: 0.9697 - val_loss: 0.0198 - val_accuracy: 0.9695\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 387s 826ms/step - loss: 0.0150 - accuracy: 0.9754 - val_loss: 0.0190 - val_accuracy: 0.9707\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 385s 820ms/step - loss: 0.0136 - accuracy: 0.9780 - val_loss: 0.0183 - val_accuracy: 0.9724\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 385s 821ms/step - loss: 0.0122 - accuracy: 0.9797 - val_loss: 0.0176 - val_accuracy: 0.9731\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 384s 820ms/step - loss: 0.0117 - accuracy: 0.9807 - val_loss: 0.0153 - val_accuracy: 0.9755\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 383s 816ms/step - loss: 0.0111 - accuracy: 0.9812 - val_loss: 0.0164 - val_accuracy: 0.9770\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 387s 826ms/step - loss: 0.0107 - accuracy: 0.9830 - val_loss: 0.0166 - val_accuracy: 0.9727\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 372s 793ms/step - loss: 0.0100 - accuracy: 0.9826 - val_loss: 0.0179 - val_accuracy: 0.9740\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 370s 789ms/step - loss: 0.0104 - accuracy: 0.9819 - val_loss: 0.0185 - val_accuracy: 0.9714\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 370s 789ms/step - loss: 0.0096 - accuracy: 0.9832 - val_loss: 0.0175 - val_accuracy: 0.9748\n"
     ]
    }
   ],
   "source": [
    "model_3.compile(optimizer=tf.keras.optimizers.Adam(),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model3h=model_3.fit(x_train, y_train, shuffle=True,batch_size=128 ,epochs=10,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43cdf2a",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8f39b9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('trs.pkl', 'rb') as file:\n",
    "    train_data = pickle.load(file)\n",
    "with open('tes.pkl', 'rb') as file:\n",
    "    test_data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "672f799c",
   "metadata": {
    "executionInfo": {
     "elapsed": 7334,
     "status": "ok",
     "timestamp": 1636959950139,
     "user": {
      "displayName": "Giri Allada",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-AXTKnQR8yj4zJw6KKkggHzvhCOV-jLhuoKGi=s64",
      "userId": "07901476334297442322"
     },
     "user_tz": 420
    },
    "id": "pvqs0Bzu8W_0"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def generate_sample_positive_indices(start,end):\n",
    "    temp = range(start,end)\n",
    "    indices = []\n",
    "    while len(indices) != 45:\n",
    "        temp_index=random.sample(temp,2)\n",
    "        ti=[0,0]\n",
    "        ti[1],ti[0] = temp_index[0],temp_index[1]\n",
    "        if ti not in indices and temp_index not in indices:\n",
    "            indices.append(temp_index)\n",
    "    return indices\n",
    "def generate_sample_negative_indices(start,size,samp):\n",
    "    temp = range(start,start+10)\n",
    "    indices=[]\n",
    "    i=0\n",
    "    while len(indices)!=samp:\n",
    "        while i<size:\n",
    "            # print(i not in temp)\n",
    "            if i not in temp:\n",
    "                xy=range(i,i+10)\n",
    "                tempa =[random.sample(temp,1)[0],random.sample(xy,1)[0]]\n",
    "                ti=[0,0]\n",
    "                ti[1],ti[0] = tempa[0],tempa[1]\n",
    "                if ti not in indices and tempa not in indices:\n",
    "                    indices.append(tempa)\n",
    "                    len(indices)\n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "        i=i+10\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c7517e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 16180)\n",
      "(4500, 16180)\n",
      "(4500,)\n"
     ]
    }
   ],
   "source": [
    "y=[]\n",
    "left=[]\n",
    "right=[]\n",
    "for x in range(0,500,10):\n",
    "    positive=generate_sample_positive_indices(x,x+10)\n",
    "    negative=random.sample(generate_sample_negative_indices(x,500,49),45)\n",
    "    for i in positive:\n",
    "        left.append(train_data[i[0]])\n",
    "        right.append(train_data[i[1]])\n",
    "        y.append(1)\n",
    "    for j in negative:\n",
    "        left.append(train_data[j[0]])\n",
    "        right.append(train_data[j[1]])\n",
    "        y.append(0)\n",
    "print(np.array(left).shape)\n",
    "print(np.array(right).shape)\n",
    "print(np.array(y).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e54a2219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "def preprocess_sound(sound):\n",
    "    processed_sound=np.abs(librosa.stft(np.array(sound), n_fft=1024, hop_length=512))\n",
    "    return(processed_sound)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "bcb60f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_L_Train=[]\n",
    "S_R_Train=[]\n",
    "for l in left:\n",
    "    S_L_Train.append(preprocess_sound(l))\n",
    "for r in right:\n",
    "    S_R_Train.append(preprocess_sound(r))\n",
    "S_L_Train=np.array(S_L_Train).transpose(0,2,1)\n",
    "S_R_Train=np.array(S_R_Train).transpose(0,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f366d357",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 190,
     "status": "ok",
     "timestamp": 1636959940615,
     "user": {
      "displayName": "Giri Allada",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-AXTKnQR8yj4zJw6KKkggHzvhCOV-jLhuoKGi=s64",
      "userId": "07901476334297442322"
     },
     "user_tz": 420
    },
    "id": "2spNoJ_Yyx9e",
    "outputId": "9894b655-92a3-405a-8114-71dc61dd8495"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(760, 22631)\n",
      "(760, 22631)\n",
      "(760,)\n"
     ]
    }
   ],
   "source": [
    "y_test=[]\n",
    "left_test=[]\n",
    "right_test=[]\n",
    "for x in range(0,200,10):\n",
    "    positive=random.sample(generate_sample_positive_indices(x,x+10),19)\n",
    "    negative=random.sample(generate_sample_negative_indices(x,200,19),19)\n",
    "    for i in positive:\n",
    "        left_test.append(test_data[i[0]])\n",
    "        right_test.append(test_data[i[1]])\n",
    "        y_test.append(1)\n",
    "    for j in negative:\n",
    "        left_test.append(test_data[j[0]])\n",
    "        right_test.append(test_data[j[1]])\n",
    "        y_test.append(0)\n",
    "print(np.array(left_test).shape)\n",
    "print(np.array(right_test).shape)\n",
    "print(np.array(y_test).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ea8b632c",
   "metadata": {
    "executionInfo": {
     "elapsed": 2205,
     "status": "ok",
     "timestamp": 1636959942816,
     "user": {
      "displayName": "Giri Allada",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-AXTKnQR8yj4zJw6KKkggHzvhCOV-jLhuoKGi=s64",
      "userId": "07901476334297442322"
     },
     "user_tz": 420
    },
    "id": "qF4R3TSW1G19"
   },
   "outputs": [],
   "source": [
    "S_L_Test=[]\n",
    "S_R_Test=[]\n",
    "for l in left_test:\n",
    "    S_L_Test.append(preprocess_sound(l))\n",
    "for r in right_test:\n",
    "    S_R_Test.append(preprocess_sound(r))\n",
    "S_L_Test=np.array(S_L_Test).transpose(0,2,1)\n",
    "S_R_Test=np.array(S_R_Test).transpose(0,2,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ab6b33c0",
   "metadata": {
    "executionInfo": {
     "elapsed": 7334,
     "status": "ok",
     "timestamp": 1636959950139,
     "user": {
      "displayName": "Giri Allada",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-AXTKnQR8yj4zJw6KKkggHzvhCOV-jLhuoKGi=s64",
      "userId": "07901476334297442322"
     },
     "user_tz": 420
    },
    "id": "pvqs0Bzu8W_0"
   },
   "outputs": [],
   "source": [
    "left_input = tf.keras.layers.Input(shape=(None,513))\n",
    "right_input = tf.keras.layers.Input(shape=(None,513))\n",
    "siaml = tf.keras.Sequential()\n",
    "siaml.add(tf.keras.layers.GRU(activation='tanh',units=512))\n",
    "siaml.add(tf.keras.layers.GRU(activation='tanh',units=512))\n",
    "siamr = tf.keras.Sequential()\n",
    "siamr.add(tf.keras.layers.GRU(activation='tanh',units=512))\n",
    "siamr.add(tf.keras.layers.GRU(activation='tanh',units=512))\n",
    "encoded_l = siaml(left_input)\n",
    "encoded_r = siamr(right_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2239a7e4",
   "metadata": {
    "executionInfo": {
     "elapsed": 7334,
     "status": "ok",
     "timestamp": 1636959950139,
     "user": {
      "displayName": "Giri Allada",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-AXTKnQR8yj4zJw6KKkggHzvhCOV-jLhuoKGi=s64",
      "userId": "07901476334297442322"
     },
     "user_tz": 420
    },
    "id": "pvqs0Bzu8W_0"
   },
   "outputs": [],
   "source": [
    "L1_layer = tf.keras.layers.Lambda(lambda tensors:tf.reduce_sum( tf.multiply( tensors[0], tensors[1] ), 1 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "23c9405e",
   "metadata": {
    "executionInfo": {
     "elapsed": 7334,
     "status": "ok",
     "timestamp": 1636959950139,
     "user": {
      "displayName": "Giri Allada",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-AXTKnQR8yj4zJw6KKkggHzvhCOV-jLhuoKGi=s64",
      "userId": "07901476334297442322"
     },
     "user_tz": 420
    },
    "id": "pvqs0Bzu8W_0"
   },
   "outputs": [],
   "source": [
    "siamese_net = tf.keras.Model(inputs=[left_input,right_input],outputs= tf.keras.layers.Dense(1,activation='sigmoid')(L1_layer([encoded_l, encoded_r])))\n",
    "siamese_net.compile(loss=tf.keras.losses.BinaryCrossentropy() , optimizer=tf.keras.optimizers.Adam(learning_rate=0.000001), metrics= [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9873873f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 561514,
     "status": "ok",
     "timestamp": 1636960511644,
     "user": {
      "displayName": "Giri Allada",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-AXTKnQR8yj4zJw6KKkggHzvhCOV-jLhuoKGi=s64",
      "userId": "07901476334297442322"
     },
     "user_tz": 420
    },
    "id": "KoFxaGSs8LEt",
    "outputId": "e4406c13-af98-4728-bdcc-917eacd9bc34",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "90/90 [==============================] - 51s 539ms/step - loss: 0.7325 - accuracy: 0.5060 - val_loss: 0.7289 - val_accuracy: 0.5092\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 45s 498ms/step - loss: 0.7174 - accuracy: 0.5091 - val_loss: 0.7161 - val_accuracy: 0.5158\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 45s 496ms/step - loss: 0.7071 - accuracy: 0.5200 - val_loss: 0.7070 - val_accuracy: 0.5289\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 45s 497ms/step - loss: 0.6985 - accuracy: 0.5316 - val_loss: 0.6963 - val_accuracy: 0.5250\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 45s 496ms/step - loss: 0.6911 - accuracy: 0.5416 - val_loss: 0.6891 - val_accuracy: 0.5421\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 46s 509ms/step - loss: 0.6845 - accuracy: 0.5496 - val_loss: 0.6843 - val_accuracy: 0.5487\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 45s 500ms/step - loss: 0.6788 - accuracy: 0.5636 - val_loss: 0.6778 - val_accuracy: 0.5500\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 46s 511ms/step - loss: 0.6733 - accuracy: 0.5751 - val_loss: 0.6728 - val_accuracy: 0.5592\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 44s 485ms/step - loss: 0.6684 - accuracy: 0.5807 - val_loss: 0.6701 - val_accuracy: 0.5711\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 46s 508ms/step - loss: 0.6635 - accuracy: 0.5913 - val_loss: 0.6625 - val_accuracy: 0.5684\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 49s 545ms/step - loss: 0.6586 - accuracy: 0.6024 - val_loss: 0.6580 - val_accuracy: 0.5737\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 45s 501ms/step - loss: 0.6540 - accuracy: 0.6098 - val_loss: 0.6561 - val_accuracy: 0.5895\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 44s 489ms/step - loss: 0.6499 - accuracy: 0.6180 - val_loss: 0.6517 - val_accuracy: 0.6013\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 47s 517ms/step - loss: 0.6455 - accuracy: 0.6249 - val_loss: 0.6485 - val_accuracy: 0.6066\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 44s 487ms/step - loss: 0.6415 - accuracy: 0.6338 - val_loss: 0.6449 - val_accuracy: 0.6026\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 44s 485ms/step - loss: 0.6376 - accuracy: 0.6391 - val_loss: 0.6412 - val_accuracy: 0.6105\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 44s 486ms/step - loss: 0.6334 - accuracy: 0.6447 - val_loss: 0.6382 - val_accuracy: 0.6132\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 45s 500ms/step - loss: 0.6295 - accuracy: 0.6558 - val_loss: 0.6374 - val_accuracy: 0.6171\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 44s 493ms/step - loss: 0.6260 - accuracy: 0.6658 - val_loss: 0.6333 - val_accuracy: 0.6184\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 45s 505ms/step - loss: 0.6223 - accuracy: 0.6678 - val_loss: 0.6291 - val_accuracy: 0.6171\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 44s 492ms/step - loss: 0.6185 - accuracy: 0.6753 - val_loss: 0.6266 - val_accuracy: 0.6197\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 44s 490ms/step - loss: 0.6150 - accuracy: 0.6807 - val_loss: 0.6251 - val_accuracy: 0.6395\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 45s 498ms/step - loss: 0.6115 - accuracy: 0.6858 - val_loss: 0.6225 - val_accuracy: 0.6329\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - 44s 494ms/step - loss: 0.6081 - accuracy: 0.6931 - val_loss: 0.6210 - val_accuracy: 0.6434\n",
      "Epoch 25/200\n",
      "90/90 [==============================] - 45s 495ms/step - loss: 0.6045 - accuracy: 0.6951 - val_loss: 0.6183 - val_accuracy: 0.6421\n",
      "Epoch 26/200\n",
      "90/90 [==============================] - 44s 492ms/step - loss: 0.6014 - accuracy: 0.6982 - val_loss: 0.6158 - val_accuracy: 0.6408\n",
      "Epoch 27/200\n",
      "90/90 [==============================] - 44s 489ms/step - loss: 0.5983 - accuracy: 0.7004 - val_loss: 0.6127 - val_accuracy: 0.6395\n",
      "Epoch 28/200\n",
      "90/90 [==============================] - 43s 482ms/step - loss: 0.5948 - accuracy: 0.7091 - val_loss: 0.6113 - val_accuracy: 0.6421\n",
      "Epoch 29/200\n",
      "90/90 [==============================] - 46s 511ms/step - loss: 0.5914 - accuracy: 0.7118 - val_loss: 0.6091 - val_accuracy: 0.6434\n",
      "Epoch 30/200\n",
      "90/90 [==============================] - 48s 533ms/step - loss: 0.5882 - accuracy: 0.7147 - val_loss: 0.6091 - val_accuracy: 0.6592\n",
      "Epoch 31/200\n",
      "90/90 [==============================] - 48s 535ms/step - loss: 0.5851 - accuracy: 0.7167 - val_loss: 0.6041 - val_accuracy: 0.6434\n",
      "Epoch 32/200\n",
      "90/90 [==============================] - 46s 507ms/step - loss: 0.5816 - accuracy: 0.7198 - val_loss: 0.6056 - val_accuracy: 0.6645\n",
      "Epoch 33/200\n",
      "90/90 [==============================] - 45s 506ms/step - loss: 0.5788 - accuracy: 0.7231 - val_loss: 0.6015 - val_accuracy: 0.6566\n",
      "Epoch 34/200\n",
      "90/90 [==============================] - 44s 491ms/step - loss: 0.5756 - accuracy: 0.7282 - val_loss: 0.5998 - val_accuracy: 0.6618\n",
      "Epoch 35/200\n",
      "90/90 [==============================] - 47s 518ms/step - loss: 0.5728 - accuracy: 0.7311 - val_loss: 0.5980 - val_accuracy: 0.6632\n",
      "Epoch 36/200\n",
      "90/90 [==============================] - 46s 515ms/step - loss: 0.5697 - accuracy: 0.7329 - val_loss: 0.5980 - val_accuracy: 0.6684\n",
      "Epoch 37/200\n",
      "90/90 [==============================] - 46s 515ms/step - loss: 0.5666 - accuracy: 0.7369 - val_loss: 0.5951 - val_accuracy: 0.6645\n",
      "Epoch 38/200\n",
      "90/90 [==============================] - 46s 509ms/step - loss: 0.5635 - accuracy: 0.7431 - val_loss: 0.5940 - val_accuracy: 0.6658\n",
      "Epoch 39/200\n",
      "90/90 [==============================] - 44s 495ms/step - loss: 0.5610 - accuracy: 0.7462 - val_loss: 0.5928 - val_accuracy: 0.6724\n",
      "Epoch 40/200\n",
      "90/90 [==============================] - 45s 499ms/step - loss: 0.5578 - accuracy: 0.7482 - val_loss: 0.5905 - val_accuracy: 0.6684\n",
      "Epoch 41/200\n",
      "90/90 [==============================] - 44s 485ms/step - loss: 0.5547 - accuracy: 0.7527 - val_loss: 0.5923 - val_accuracy: 0.6763\n",
      "Epoch 42/200\n",
      "90/90 [==============================] - 46s 517ms/step - loss: 0.5522 - accuracy: 0.7531 - val_loss: 0.5880 - val_accuracy: 0.6763\n",
      "Epoch 43/200\n",
      "90/90 [==============================] - 46s 512ms/step - loss: 0.5490 - accuracy: 0.7533 - val_loss: 0.5884 - val_accuracy: 0.6776\n",
      "Epoch 44/200\n",
      "90/90 [==============================] - 46s 509ms/step - loss: 0.5464 - accuracy: 0.7573 - val_loss: 0.5896 - val_accuracy: 0.6750\n",
      "Epoch 45/200\n",
      "90/90 [==============================] - 46s 506ms/step - loss: 0.5435 - accuracy: 0.7604 - val_loss: 0.5832 - val_accuracy: 0.6776\n",
      "Epoch 46/200\n",
      "90/90 [==============================] - 46s 516ms/step - loss: 0.5408 - accuracy: 0.7636 - val_loss: 0.5847 - val_accuracy: 0.6803\n",
      "Epoch 47/200\n",
      "90/90 [==============================] - 50s 553ms/step - loss: 0.5381 - accuracy: 0.7651 - val_loss: 0.5843 - val_accuracy: 0.6803\n",
      "Epoch 48/200\n",
      "90/90 [==============================] - 47s 523ms/step - loss: 0.5353 - accuracy: 0.7651 - val_loss: 0.5807 - val_accuracy: 0.6776\n",
      "Epoch 49/200\n",
      "90/90 [==============================] - 46s 510ms/step - loss: 0.5322 - accuracy: 0.7667 - val_loss: 0.5771 - val_accuracy: 0.6842\n",
      "Epoch 50/200\n",
      "90/90 [==============================] - 45s 499ms/step - loss: 0.5300 - accuracy: 0.7682 - val_loss: 0.5772 - val_accuracy: 0.6789\n",
      "Epoch 51/200\n",
      "90/90 [==============================] - 44s 493ms/step - loss: 0.5271 - accuracy: 0.7736 - val_loss: 0.5816 - val_accuracy: 0.6789\n",
      "Epoch 52/200\n",
      "90/90 [==============================] - 45s 503ms/step - loss: 0.5246 - accuracy: 0.7740 - val_loss: 0.5792 - val_accuracy: 0.6776\n",
      "Epoch 53/200\n",
      "90/90 [==============================] - 44s 494ms/step - loss: 0.5220 - accuracy: 0.7760 - val_loss: 0.5756 - val_accuracy: 0.6750\n",
      "Epoch 54/200\n",
      "90/90 [==============================] - 47s 523ms/step - loss: 0.5190 - accuracy: 0.7747 - val_loss: 0.5745 - val_accuracy: 0.6750\n",
      "Epoch 55/200\n",
      "90/90 [==============================] - 46s 506ms/step - loss: 0.5167 - accuracy: 0.7784 - val_loss: 0.5729 - val_accuracy: 0.6829\n",
      "Epoch 56/200\n",
      "90/90 [==============================] - 46s 516ms/step - loss: 0.5140 - accuracy: 0.7818 - val_loss: 0.5713 - val_accuracy: 0.6842\n",
      "Epoch 57/200\n",
      "90/90 [==============================] - 47s 517ms/step - loss: 0.5114 - accuracy: 0.7816 - val_loss: 0.5696 - val_accuracy: 0.6829\n",
      "Epoch 58/200\n",
      "90/90 [==============================] - 46s 510ms/step - loss: 0.5089 - accuracy: 0.7829 - val_loss: 0.5709 - val_accuracy: 0.6829\n",
      "Epoch 59/200\n",
      "90/90 [==============================] - 46s 513ms/step - loss: 0.5064 - accuracy: 0.7836 - val_loss: 0.5671 - val_accuracy: 0.6842\n",
      "Epoch 60/200\n",
      "90/90 [==============================] - 46s 510ms/step - loss: 0.5041 - accuracy: 0.7873 - val_loss: 0.5691 - val_accuracy: 0.6776\n",
      "Epoch 61/200\n",
      "90/90 [==============================] - 46s 511ms/step - loss: 0.5014 - accuracy: 0.7860 - val_loss: 0.5715 - val_accuracy: 0.6763\n",
      "Epoch 62/200\n",
      "90/90 [==============================] - 46s 511ms/step - loss: 0.4990 - accuracy: 0.7898 - val_loss: 0.5680 - val_accuracy: 0.6763\n",
      "Epoch 63/200\n",
      "90/90 [==============================] - 45s 502ms/step - loss: 0.4963 - accuracy: 0.7909 - val_loss: 0.5672 - val_accuracy: 0.6816\n",
      "Epoch 64/200\n",
      "90/90 [==============================] - 44s 485ms/step - loss: 0.4940 - accuracy: 0.7916 - val_loss: 0.5658 - val_accuracy: 0.6816\n",
      "Epoch 65/200\n",
      "90/90 [==============================] - 44s 493ms/step - loss: 0.4918 - accuracy: 0.7953 - val_loss: 0.5701 - val_accuracy: 0.6750\n",
      "Epoch 66/200\n",
      "90/90 [==============================] - 45s 505ms/step - loss: 0.4896 - accuracy: 0.7949 - val_loss: 0.5655 - val_accuracy: 0.6803\n",
      "Epoch 67/200\n",
      "90/90 [==============================] - 46s 514ms/step - loss: 0.4868 - accuracy: 0.7978 - val_loss: 0.5622 - val_accuracy: 0.6842\n",
      "Epoch 68/200\n",
      "90/90 [==============================] - 46s 514ms/step - loss: 0.4843 - accuracy: 0.7998 - val_loss: 0.5617 - val_accuracy: 0.6868\n",
      "Epoch 69/200\n",
      "90/90 [==============================] - 43s 483ms/step - loss: 0.4823 - accuracy: 0.8013 - val_loss: 0.5613 - val_accuracy: 0.6842\n",
      "Epoch 70/200\n",
      "90/90 [==============================] - 44s 485ms/step - loss: 0.4798 - accuracy: 0.8044 - val_loss: 0.5625 - val_accuracy: 0.6829\n",
      "Epoch 71/200\n",
      "90/90 [==============================] - 45s 500ms/step - loss: 0.4774 - accuracy: 0.8044 - val_loss: 0.5617 - val_accuracy: 0.6868\n",
      "Epoch 72/200\n",
      "90/90 [==============================] - 45s 501ms/step - loss: 0.4750 - accuracy: 0.8051 - val_loss: 0.5595 - val_accuracy: 0.6895\n",
      "Epoch 73/200\n",
      "90/90 [==============================] - 46s 510ms/step - loss: 0.4729 - accuracy: 0.8071 - val_loss: 0.5607 - val_accuracy: 0.6868\n",
      "Epoch 74/200\n",
      "90/90 [==============================] - 45s 495ms/step - loss: 0.4707 - accuracy: 0.8082 - val_loss: 0.5642 - val_accuracy: 0.6895\n",
      "Epoch 75/200\n",
      "90/90 [==============================] - 44s 491ms/step - loss: 0.4686 - accuracy: 0.8120 - val_loss: 0.5628 - val_accuracy: 0.6921\n",
      "Epoch 76/200\n",
      "90/90 [==============================] - 44s 486ms/step - loss: 0.4665 - accuracy: 0.8131 - val_loss: 0.5596 - val_accuracy: 0.6908\n",
      "Epoch 77/200\n",
      "90/90 [==============================] - 44s 484ms/step - loss: 0.4641 - accuracy: 0.8158 - val_loss: 0.5582 - val_accuracy: 0.6947\n",
      "Epoch 78/200\n",
      "90/90 [==============================] - 43s 483ms/step - loss: 0.4617 - accuracy: 0.8142 - val_loss: 0.5570 - val_accuracy: 0.6961\n",
      "Epoch 79/200\n",
      "90/90 [==============================] - 44s 495ms/step - loss: 0.4597 - accuracy: 0.8153 - val_loss: 0.5584 - val_accuracy: 0.6974\n",
      "Epoch 80/200\n",
      "90/90 [==============================] - 44s 492ms/step - loss: 0.4576 - accuracy: 0.8147 - val_loss: 0.5560 - val_accuracy: 0.6947\n",
      "Epoch 81/200\n",
      "90/90 [==============================] - 46s 512ms/step - loss: 0.4554 - accuracy: 0.8182 - val_loss: 0.5578 - val_accuracy: 0.6961\n",
      "Epoch 82/200\n",
      "90/90 [==============================] - 45s 497ms/step - loss: 0.4533 - accuracy: 0.8200 - val_loss: 0.5559 - val_accuracy: 0.6961\n",
      "Epoch 83/200\n",
      "90/90 [==============================] - 48s 537ms/step - loss: 0.4512 - accuracy: 0.8202 - val_loss: 0.5607 - val_accuracy: 0.6974\n",
      "Epoch 84/200\n",
      "90/90 [==============================] - 44s 494ms/step - loss: 0.4492 - accuracy: 0.8211 - val_loss: 0.5581 - val_accuracy: 0.7039\n",
      "Epoch 85/200\n",
      "90/90 [==============================] - 45s 501ms/step - loss: 0.4471 - accuracy: 0.8222 - val_loss: 0.5551 - val_accuracy: 0.7053\n",
      "Epoch 86/200\n",
      "90/90 [==============================] - 45s 499ms/step - loss: 0.4448 - accuracy: 0.8242 - val_loss: 0.5547 - val_accuracy: 0.7053\n",
      "Epoch 87/200\n",
      "90/90 [==============================] - 44s 489ms/step - loss: 0.4428 - accuracy: 0.8247 - val_loss: 0.5535 - val_accuracy: 0.7026\n",
      "Epoch 88/200\n",
      "90/90 [==============================] - 44s 490ms/step - loss: 0.4410 - accuracy: 0.8267 - val_loss: 0.5539 - val_accuracy: 0.7039\n",
      "Epoch 89/200\n",
      "90/90 [==============================] - 44s 493ms/step - loss: 0.4389 - accuracy: 0.8271 - val_loss: 0.5507 - val_accuracy: 0.7053\n",
      "Epoch 90/200\n",
      "90/90 [==============================] - 45s 500ms/step - loss: 0.4367 - accuracy: 0.8287 - val_loss: 0.5548 - val_accuracy: 0.7079\n",
      "Epoch 91/200\n",
      "90/90 [==============================] - 45s 501ms/step - loss: 0.4347 - accuracy: 0.8296 - val_loss: 0.5491 - val_accuracy: 0.7053\n",
      "Epoch 92/200\n",
      "90/90 [==============================] - 45s 499ms/step - loss: 0.4330 - accuracy: 0.8296 - val_loss: 0.5502 - val_accuracy: 0.7053\n",
      "Epoch 93/200\n",
      "90/90 [==============================] - 45s 498ms/step - loss: 0.4312 - accuracy: 0.8313 - val_loss: 0.5531 - val_accuracy: 0.7039\n",
      "Epoch 94/200\n",
      "90/90 [==============================] - 45s 497ms/step - loss: 0.4292 - accuracy: 0.8313 - val_loss: 0.5523 - val_accuracy: 0.7053\n",
      "Epoch 95/200\n",
      "90/90 [==============================] - 45s 497ms/step - loss: 0.4270 - accuracy: 0.8307 - val_loss: 0.5471 - val_accuracy: 0.7053\n",
      "Epoch 96/200\n",
      "90/90 [==============================] - 45s 500ms/step - loss: 0.4254 - accuracy: 0.8324 - val_loss: 0.5495 - val_accuracy: 0.7053\n",
      "Epoch 97/200\n",
      "90/90 [==============================] - 46s 512ms/step - loss: 0.4233 - accuracy: 0.8362 - val_loss: 0.5588 - val_accuracy: 0.6947\n",
      "Epoch 98/200\n",
      "90/90 [==============================] - 46s 515ms/step - loss: 0.4220 - accuracy: 0.8338 - val_loss: 0.5489 - val_accuracy: 0.7066\n",
      "Epoch 99/200\n",
      "90/90 [==============================] - 44s 491ms/step - loss: 0.4200 - accuracy: 0.8362 - val_loss: 0.5521 - val_accuracy: 0.7026\n",
      "Epoch 100/200\n",
      "90/90 [==============================] - 46s 517ms/step - loss: 0.4177 - accuracy: 0.8404 - val_loss: 0.5496 - val_accuracy: 0.7066\n",
      "Epoch 101/200\n",
      "90/90 [==============================] - 47s 518ms/step - loss: 0.4159 - accuracy: 0.8376 - val_loss: 0.5514 - val_accuracy: 0.7026\n",
      "Epoch 102/200\n",
      "90/90 [==============================] - 47s 518ms/step - loss: 0.4141 - accuracy: 0.8422 - val_loss: 0.5502 - val_accuracy: 0.7026\n",
      "Epoch 103/200\n",
      "90/90 [==============================] - 45s 501ms/step - loss: 0.4123 - accuracy: 0.8400 - val_loss: 0.5548 - val_accuracy: 0.7066\n",
      "Epoch 104/200\n",
      "90/90 [==============================] - 45s 499ms/step - loss: 0.4105 - accuracy: 0.8422 - val_loss: 0.5513 - val_accuracy: 0.7026\n",
      "Epoch 105/200\n",
      "90/90 [==============================] - 45s 499ms/step - loss: 0.4087 - accuracy: 0.8424 - val_loss: 0.5461 - val_accuracy: 0.7118\n",
      "Epoch 106/200\n",
      "90/90 [==============================] - 45s 496ms/step - loss: 0.4069 - accuracy: 0.8431 - val_loss: 0.5530 - val_accuracy: 0.7026\n",
      "Epoch 107/200\n",
      "90/90 [==============================] - 45s 500ms/step - loss: 0.4054 - accuracy: 0.8431 - val_loss: 0.5567 - val_accuracy: 0.7013\n",
      "Epoch 108/200\n",
      "90/90 [==============================] - 45s 495ms/step - loss: 0.4039 - accuracy: 0.8420 - val_loss: 0.5518 - val_accuracy: 0.7053\n",
      "Epoch 109/200\n",
      "90/90 [==============================] - 45s 503ms/step - loss: 0.4019 - accuracy: 0.8433 - val_loss: 0.5493 - val_accuracy: 0.7066\n",
      "Epoch 110/200\n",
      "90/90 [==============================] - 46s 509ms/step - loss: 0.4000 - accuracy: 0.8462 - val_loss: 0.5558 - val_accuracy: 0.7013\n",
      "Epoch 111/200\n",
      "90/90 [==============================] - 44s 486ms/step - loss: 0.3983 - accuracy: 0.8456 - val_loss: 0.5453 - val_accuracy: 0.7105\n",
      "Epoch 112/200\n",
      "90/90 [==============================] - 43s 479ms/step - loss: 0.3968 - accuracy: 0.8458 - val_loss: 0.5578 - val_accuracy: 0.7013\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 43s 478ms/step - loss: 0.3952 - accuracy: 0.8471 - val_loss: 0.5594 - val_accuracy: 0.7000\n",
      "Epoch 114/200\n",
      "90/90 [==============================] - 43s 479ms/step - loss: 0.3934 - accuracy: 0.8484 - val_loss: 0.5496 - val_accuracy: 0.7079\n",
      "Epoch 115/200\n",
      "90/90 [==============================] - 43s 478ms/step - loss: 0.3917 - accuracy: 0.8487 - val_loss: 0.5495 - val_accuracy: 0.7079\n",
      "Epoch 116/200\n",
      "90/90 [==============================] - 43s 478ms/step - loss: 0.3901 - accuracy: 0.8511 - val_loss: 0.5532 - val_accuracy: 0.7053\n",
      "Epoch 117/200\n",
      "90/90 [==============================] - 43s 477ms/step - loss: 0.3884 - accuracy: 0.8504 - val_loss: 0.5617 - val_accuracy: 0.7026\n",
      "Epoch 118/200\n",
      "90/90 [==============================] - 43s 479ms/step - loss: 0.3869 - accuracy: 0.8516 - val_loss: 0.5549 - val_accuracy: 0.7066\n",
      "Epoch 119/200\n",
      "90/90 [==============================] - 43s 477ms/step - loss: 0.3852 - accuracy: 0.8529 - val_loss: 0.5484 - val_accuracy: 0.7092\n",
      "Epoch 120/200\n",
      "90/90 [==============================] - 43s 477ms/step - loss: 0.3836 - accuracy: 0.8522 - val_loss: 0.5527 - val_accuracy: 0.7053\n",
      "Epoch 121/200\n",
      "90/90 [==============================] - 43s 479ms/step - loss: 0.3821 - accuracy: 0.8518 - val_loss: 0.5521 - val_accuracy: 0.7066\n",
      "Epoch 122/200\n",
      "90/90 [==============================] - 43s 476ms/step - loss: 0.3805 - accuracy: 0.8533 - val_loss: 0.5493 - val_accuracy: 0.7105\n",
      "Epoch 123/200\n",
      "90/90 [==============================] - 43s 480ms/step - loss: 0.3788 - accuracy: 0.8529 - val_loss: 0.5488 - val_accuracy: 0.7145\n",
      "Epoch 124/200\n",
      "90/90 [==============================] - 43s 476ms/step - loss: 0.3773 - accuracy: 0.8531 - val_loss: 0.5485 - val_accuracy: 0.7132\n",
      "Epoch 125/200\n",
      "90/90 [==============================] - 44s 491ms/step - loss: 0.3757 - accuracy: 0.8544 - val_loss: 0.5529 - val_accuracy: 0.7079\n",
      "Epoch 126/200\n",
      "90/90 [==============================] - 43s 476ms/step - loss: 0.3745 - accuracy: 0.8547 - val_loss: 0.5483 - val_accuracy: 0.7145\n",
      "Epoch 127/200\n",
      "90/90 [==============================] - 43s 477ms/step - loss: 0.3728 - accuracy: 0.8560 - val_loss: 0.5492 - val_accuracy: 0.7184\n",
      "Epoch 128/200\n",
      "90/90 [==============================] - 43s 476ms/step - loss: 0.3711 - accuracy: 0.8571 - val_loss: 0.5552 - val_accuracy: 0.7079\n",
      "Epoch 129/200\n",
      "90/90 [==============================] - 43s 476ms/step - loss: 0.3698 - accuracy: 0.8587 - val_loss: 0.5547 - val_accuracy: 0.7105\n",
      "Epoch 130/200\n",
      "90/90 [==============================] - 43s 476ms/step - loss: 0.3683 - accuracy: 0.8578 - val_loss: 0.5475 - val_accuracy: 0.7171\n",
      "Epoch 131/200\n",
      "90/90 [==============================] - 43s 476ms/step - loss: 0.3669 - accuracy: 0.8580 - val_loss: 0.5518 - val_accuracy: 0.7184\n",
      "Epoch 132/200\n",
      "90/90 [==============================] - 43s 477ms/step - loss: 0.3652 - accuracy: 0.8613 - val_loss: 0.5513 - val_accuracy: 0.7171\n",
      "Epoch 133/200\n",
      "90/90 [==============================] - 43s 475ms/step - loss: 0.3638 - accuracy: 0.8587 - val_loss: 0.5516 - val_accuracy: 0.7224\n",
      "Epoch 134/200\n",
      "90/90 [==============================] - 43s 477ms/step - loss: 0.3623 - accuracy: 0.8587 - val_loss: 0.5634 - val_accuracy: 0.7066\n",
      "Epoch 135/200\n",
      "90/90 [==============================] - 43s 477ms/step - loss: 0.3609 - accuracy: 0.8598 - val_loss: 0.5450 - val_accuracy: 0.7197\n",
      "Epoch 136/200\n",
      "90/90 [==============================] - 43s 477ms/step - loss: 0.3592 - accuracy: 0.8629 - val_loss: 0.5610 - val_accuracy: 0.7158\n",
      "Epoch 137/200\n",
      "90/90 [==============================] - 43s 478ms/step - loss: 0.3583 - accuracy: 0.8622 - val_loss: 0.5569 - val_accuracy: 0.7158\n",
      "Epoch 138/200\n",
      "90/90 [==============================] - 43s 478ms/step - loss: 0.3565 - accuracy: 0.8629 - val_loss: 0.5564 - val_accuracy: 0.7145\n",
      "Epoch 139/200\n",
      "90/90 [==============================] - 43s 478ms/step - loss: 0.3552 - accuracy: 0.8653 - val_loss: 0.5508 - val_accuracy: 0.7237\n",
      "Epoch 140/200\n",
      "90/90 [==============================] - 43s 477ms/step - loss: 0.3536 - accuracy: 0.8644 - val_loss: 0.5489 - val_accuracy: 0.7237\n",
      "Epoch 141/200\n",
      "90/90 [==============================] - 43s 480ms/step - loss: 0.3524 - accuracy: 0.8660 - val_loss: 0.5560 - val_accuracy: 0.7171\n",
      "Epoch 142/200\n",
      "90/90 [==============================] - 43s 479ms/step - loss: 0.3508 - accuracy: 0.8649 - val_loss: 0.5410 - val_accuracy: 0.7316\n",
      "Epoch 143/200\n",
      "90/90 [==============================] - 43s 477ms/step - loss: 0.3497 - accuracy: 0.8667 - val_loss: 0.5537 - val_accuracy: 0.7211\n",
      "Epoch 144/200\n",
      "90/90 [==============================] - 43s 481ms/step - loss: 0.3482 - accuracy: 0.8669 - val_loss: 0.5537 - val_accuracy: 0.7211\n",
      "Epoch 145/200\n",
      "90/90 [==============================] - 43s 479ms/step - loss: 0.3468 - accuracy: 0.8671 - val_loss: 0.5483 - val_accuracy: 0.7250\n",
      "Epoch 146/200\n",
      "90/90 [==============================] - 43s 482ms/step - loss: 0.3458 - accuracy: 0.8682 - val_loss: 0.5505 - val_accuracy: 0.7237\n",
      "Epoch 147/200\n",
      "90/90 [==============================] - 44s 485ms/step - loss: 0.3442 - accuracy: 0.8682 - val_loss: 0.5581 - val_accuracy: 0.7237\n",
      "Epoch 148/200\n",
      "90/90 [==============================] - 44s 486ms/step - loss: 0.3429 - accuracy: 0.8689 - val_loss: 0.5521 - val_accuracy: 0.7211\n",
      "Epoch 149/200\n",
      "90/90 [==============================] - 44s 486ms/step - loss: 0.3414 - accuracy: 0.8693 - val_loss: 0.5529 - val_accuracy: 0.7224\n",
      "Epoch 150/200\n",
      "90/90 [==============================] - 44s 489ms/step - loss: 0.3400 - accuracy: 0.8729 - val_loss: 0.5586 - val_accuracy: 0.7237\n",
      "Epoch 151/200\n",
      "90/90 [==============================] - 44s 490ms/step - loss: 0.3389 - accuracy: 0.8722 - val_loss: 0.5518 - val_accuracy: 0.7263\n",
      "Epoch 152/200\n",
      "90/90 [==============================] - 44s 491ms/step - loss: 0.3375 - accuracy: 0.8716 - val_loss: 0.5521 - val_accuracy: 0.7263\n",
      "Epoch 153/200\n",
      "90/90 [==============================] - 44s 495ms/step - loss: 0.3363 - accuracy: 0.8731 - val_loss: 0.5560 - val_accuracy: 0.7237\n",
      "Epoch 154/200\n",
      "90/90 [==============================] - 44s 491ms/step - loss: 0.3349 - accuracy: 0.8729 - val_loss: 0.5506 - val_accuracy: 0.7276\n",
      "Epoch 155/200\n",
      "90/90 [==============================] - 45s 496ms/step - loss: 0.3338 - accuracy: 0.8738 - val_loss: 0.5532 - val_accuracy: 0.7263\n",
      "Epoch 156/200\n",
      "90/90 [==============================] - 45s 495ms/step - loss: 0.3323 - accuracy: 0.8744 - val_loss: 0.5530 - val_accuracy: 0.7289\n",
      "Epoch 157/200\n",
      "90/90 [==============================] - 44s 493ms/step - loss: 0.3312 - accuracy: 0.8749 - val_loss: 0.5527 - val_accuracy: 0.7316\n",
      "Epoch 158/200\n",
      "90/90 [==============================] - 44s 493ms/step - loss: 0.3299 - accuracy: 0.8742 - val_loss: 0.5597 - val_accuracy: 0.7237\n",
      "Epoch 159/200\n",
      "90/90 [==============================] - 44s 491ms/step - loss: 0.3286 - accuracy: 0.8742 - val_loss: 0.5601 - val_accuracy: 0.7250\n",
      "Epoch 160/200\n",
      "90/90 [==============================] - 44s 494ms/step - loss: 0.3276 - accuracy: 0.8764 - val_loss: 0.5523 - val_accuracy: 0.7316\n",
      "Epoch 161/200\n",
      "90/90 [==============================] - 43s 480ms/step - loss: 0.3263 - accuracy: 0.8756 - val_loss: 0.5490 - val_accuracy: 0.7355\n",
      "Epoch 162/200\n",
      "90/90 [==============================] - 43s 479ms/step - loss: 0.3251 - accuracy: 0.8764 - val_loss: 0.5513 - val_accuracy: 0.7303\n",
      "Epoch 163/200\n",
      "90/90 [==============================] - 44s 484ms/step - loss: 0.3236 - accuracy: 0.8753 - val_loss: 0.5666 - val_accuracy: 0.7224\n",
      "Epoch 164/200\n",
      "90/90 [==============================] - 43s 482ms/step - loss: 0.3222 - accuracy: 0.8796 - val_loss: 0.5482 - val_accuracy: 0.7368\n",
      "Epoch 165/200\n",
      "90/90 [==============================] - 44s 485ms/step - loss: 0.3215 - accuracy: 0.8791 - val_loss: 0.5540 - val_accuracy: 0.7368\n",
      "Epoch 166/200\n",
      "90/90 [==============================] - 43s 480ms/step - loss: 0.3205 - accuracy: 0.8771 - val_loss: 0.5561 - val_accuracy: 0.7355\n",
      "Epoch 167/200\n",
      "90/90 [==============================] - 44s 487ms/step - loss: 0.3189 - accuracy: 0.8798 - val_loss: 0.5529 - val_accuracy: 0.7382\n",
      "Epoch 168/200\n",
      "90/90 [==============================] - 44s 487ms/step - loss: 0.3175 - accuracy: 0.8793 - val_loss: 0.5526 - val_accuracy: 0.7368\n",
      "Epoch 169/200\n",
      "90/90 [==============================] - 44s 489ms/step - loss: 0.3164 - accuracy: 0.8802 - val_loss: 0.5540 - val_accuracy: 0.7355\n",
      "Epoch 170/200\n",
      "90/90 [==============================] - 44s 487ms/step - loss: 0.3150 - accuracy: 0.8833 - val_loss: 0.5650 - val_accuracy: 0.7237\n",
      "Epoch 171/200\n",
      "90/90 [==============================] - 44s 486ms/step - loss: 0.3139 - accuracy: 0.8820 - val_loss: 0.5689 - val_accuracy: 0.7184\n",
      "Epoch 172/200\n",
      "90/90 [==============================] - 44s 488ms/step - loss: 0.3128 - accuracy: 0.8827 - val_loss: 0.5644 - val_accuracy: 0.7211\n",
      "Epoch 173/200\n",
      "90/90 [==============================] - 44s 491ms/step - loss: 0.3119 - accuracy: 0.8831 - val_loss: 0.5534 - val_accuracy: 0.7408\n",
      "Epoch 174/200\n",
      "90/90 [==============================] - 45s 499ms/step - loss: 0.3104 - accuracy: 0.8831 - val_loss: 0.5619 - val_accuracy: 0.7289\n",
      "Epoch 175/200\n",
      "90/90 [==============================] - 45s 497ms/step - loss: 0.3092 - accuracy: 0.8838 - val_loss: 0.5614 - val_accuracy: 0.7316\n",
      "Epoch 176/200\n",
      "90/90 [==============================] - 44s 494ms/step - loss: 0.3081 - accuracy: 0.8833 - val_loss: 0.5791 - val_accuracy: 0.7132\n",
      "Epoch 177/200\n",
      "90/90 [==============================] - 44s 494ms/step - loss: 0.3073 - accuracy: 0.8847 - val_loss: 0.5527 - val_accuracy: 0.7421\n",
      "Epoch 178/200\n",
      "90/90 [==============================] - 45s 497ms/step - loss: 0.3063 - accuracy: 0.8867 - val_loss: 0.5617 - val_accuracy: 0.7368\n",
      "Epoch 179/200\n",
      "90/90 [==============================] - 45s 498ms/step - loss: 0.3046 - accuracy: 0.8873 - val_loss: 0.5806 - val_accuracy: 0.7132\n",
      "Epoch 180/200\n",
      "90/90 [==============================] - 45s 495ms/step - loss: 0.3041 - accuracy: 0.8847 - val_loss: 0.5675 - val_accuracy: 0.7211\n",
      "Epoch 181/200\n",
      "90/90 [==============================] - 45s 496ms/step - loss: 0.3027 - accuracy: 0.8851 - val_loss: 0.5614 - val_accuracy: 0.7355\n",
      "Epoch 182/200\n",
      "90/90 [==============================] - 44s 494ms/step - loss: 0.3013 - accuracy: 0.8887 - val_loss: 0.5781 - val_accuracy: 0.7145\n",
      "Epoch 183/200\n",
      "90/90 [==============================] - 44s 488ms/step - loss: 0.3003 - accuracy: 0.8884 - val_loss: 0.5686 - val_accuracy: 0.7250\n",
      "Epoch 184/200\n",
      "90/90 [==============================] - 46s 507ms/step - loss: 0.2994 - accuracy: 0.8889 - val_loss: 0.5570 - val_accuracy: 0.7408\n",
      "Epoch 185/200\n",
      "90/90 [==============================] - 49s 545ms/step - loss: 0.2983 - accuracy: 0.8902 - val_loss: 0.5695 - val_accuracy: 0.7211\n",
      "Epoch 186/200\n",
      "90/90 [==============================] - 47s 522ms/step - loss: 0.2969 - accuracy: 0.8909 - val_loss: 0.5566 - val_accuracy: 0.7434\n",
      "Epoch 187/200\n",
      "90/90 [==============================] - 47s 520ms/step - loss: 0.2957 - accuracy: 0.8909 - val_loss: 0.5779 - val_accuracy: 0.7184\n",
      "Epoch 188/200\n",
      "90/90 [==============================] - 46s 515ms/step - loss: 0.2953 - accuracy: 0.8904 - val_loss: 0.5679 - val_accuracy: 0.7329\n",
      "Epoch 189/200\n",
      "90/90 [==============================] - 47s 525ms/step - loss: 0.2937 - accuracy: 0.8922 - val_loss: 0.5547 - val_accuracy: 0.7368\n",
      "Epoch 190/200\n",
      "90/90 [==============================] - 47s 524ms/step - loss: 0.2930 - accuracy: 0.8922 - val_loss: 0.5725 - val_accuracy: 0.7263\n",
      "Epoch 191/200\n",
      "90/90 [==============================] - 45s 505ms/step - loss: 0.2915 - accuracy: 0.8940 - val_loss: 0.5738 - val_accuracy: 0.7263\n",
      "Epoch 192/200\n",
      "90/90 [==============================] - 45s 501ms/step - loss: 0.2903 - accuracy: 0.8940 - val_loss: 0.5677 - val_accuracy: 0.7355\n",
      "Epoch 193/200\n",
      "90/90 [==============================] - 46s 510ms/step - loss: 0.2892 - accuracy: 0.8947 - val_loss: 0.5816 - val_accuracy: 0.7211\n",
      "Epoch 194/200\n",
      "90/90 [==============================] - 47s 528ms/step - loss: 0.2884 - accuracy: 0.8944 - val_loss: 0.5656 - val_accuracy: 0.7382\n",
      "Epoch 195/200\n",
      "90/90 [==============================] - 46s 513ms/step - loss: 0.2873 - accuracy: 0.8947 - val_loss: 0.5704 - val_accuracy: 0.7329\n",
      "Epoch 196/200\n",
      "90/90 [==============================] - 45s 497ms/step - loss: 0.2864 - accuracy: 0.8949 - val_loss: 0.5707 - val_accuracy: 0.7342\n",
      "Epoch 197/200\n",
      "90/90 [==============================] - 44s 495ms/step - loss: 0.2851 - accuracy: 0.8967 - val_loss: 0.5779 - val_accuracy: 0.7250\n",
      "Epoch 198/200\n",
      "90/90 [==============================] - 46s 508ms/step - loss: 0.2842 - accuracy: 0.8971 - val_loss: 0.5698 - val_accuracy: 0.7368\n",
      "Epoch 199/200\n",
      "90/90 [==============================] - 44s 494ms/step - loss: 0.2831 - accuracy: 0.8978 - val_loss: 0.5726 - val_accuracy: 0.7316\n",
      "Epoch 200/200\n",
      "90/90 [==============================] - 48s 529ms/step - loss: 0.2820 - accuracy: 0.8984 - val_loss: 0.5753 - val_accuracy: 0.7329\n"
     ]
    }
   ],
   "source": [
    "siamh= siamese_net.fit([S_L_Train,S_R_Train],np.array(y),batch_size=50, epochs=200,shuffle=True, validation_data=([S_L_Test,S_R_Test],np.array(y_test)),validation_batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1a9324",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b385915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5504c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_audio(audio):\n",
    "    padding = np.zeros((195 - len(audio), 513))\n",
    "    padded_audio = np.concatenate((audio, padding), axis=0)\n",
    "    return padded_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3a33347",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_audio(file_path):\n",
    "    audio, sr = librosa.load(file_path, sr=None)\n",
    "    stft = librosa.stft(audio, n_fft=1024, hop_length=512)\n",
    "    magnitude = np.abs(stft)\n",
    "    return magnitude.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63c4f557",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_speech =[]\n",
    "noise =[]\n",
    "noisy_speech =[]\n",
    "directory = \"C:/Users/dassu/Downloads/timit-homework/tr/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0da1da09",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(directory):\n",
    "    if filename.startswith('trs') and filename.endswith('.wav'):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        spectrogram = load_and_process_audio(file_path)\n",
    "        spectrogram=pad_audio(spectrogram)\n",
    "        clean_speech.append(spectrogram)\n",
    "clean_speech= np.array(clean_speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69b35fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(directory):\n",
    "    if filename.startswith('trx') and filename.endswith('.wav'):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        spectrogram = load_and_process_audio(file_path)\n",
    "        spectrogram=pad_audio(spectrogram)\n",
    "        noisy_speech.append(spectrogram)\n",
    "noisy_speech = np.array(noisy_speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25e4dc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(directory):\n",
    "    if filename.startswith('trn') and filename.endswith('.wav'):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        spectrogram = load_and_process_audio(file_path)\n",
    "        spectrogram=pad_audio(spectrogram)\n",
    "        noise.append(spectrogram)\n",
    "noise = np.array(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1371ae59",
   "metadata": {},
   "outputs": [],
   "source": [
    "IBM = np.where(clean_speech > noise, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6027c19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio(file_path):\n",
    "    audio, sr = librosa.load(file_path, sr=None)\n",
    "    stft = librosa.stft(audio, n_fft=1024, hop_length=512)\n",
    "    magnitude = np.abs(stft)\n",
    "    return magnitude.T,stft,magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bb8e1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_noisy_speech=[]\n",
    "directory2 = \"C:/Users/dassu/Downloads/timit-homework/v/\"\n",
    "for filename in os.listdir(directory2):\n",
    "    if filename.startswith('vx') and filename.endswith('.wav'):\n",
    "        file_path = os.path.join(directory2, filename)\n",
    "        spectrogram,stf,mag = process_audio(file_path)\n",
    "        spectrogram=pad_audio(spectrogram)\n",
    "        valid_noisy_speech.append(spectrogram)\n",
    "valid_noisy_speech= np.array(valid_noisy_speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "336afd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_clean_speech=[]\n",
    "for filename in os.listdir(directory2):\n",
    "    if filename.startswith('vs') and filename.endswith('.wav'):\n",
    "        file_path = os.path.join(directory2, filename)\n",
    "        spectrogram,_,_ = process_audio(file_path)\n",
    "        spectrogram=pad_audio(spectrogram)\n",
    "        valid_clean_speech.append(spectrogram)\n",
    "valid_clean_speech = np.array(valid_clean_speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c622ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_noise=[]\n",
    "for filename in os.listdir(directory2):\n",
    "    if filename.startswith('vn') and filename.endswith('.wav'):\n",
    "        file_path = os.path.join(directory2, filename)\n",
    "        spectrogram,_,_ = process_audio(file_path)\n",
    "        spectrogram=pad_audio(spectrogram)\n",
    "        valid_noise.append(spectrogram)\n",
    "valid_noise = np.array(valid_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bc6b924",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(513, return_sequences=True, input_shape=( 195,513)),\n",
    "    tf.keras.layers.LSTM(513,return_sequences =True),\n",
    "    tf.keras.layers.Dense(513,activation = \"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c14ca17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4ec1bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "IBM_validation = np.where(valid_clean_speech > valid_noise, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21e7c830",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "60/60 [==============================] - 97s 2s/step - loss: 0.4411 - val_loss: 0.3673\n",
      "Epoch 2/100\n",
      "60/60 [==============================] - 95s 2s/step - loss: 0.3534 - val_loss: 0.3384\n",
      "Epoch 3/100\n",
      "60/60 [==============================] - 95s 2s/step - loss: 0.3249 - val_loss: 0.3017\n",
      "Epoch 4/100\n",
      "60/60 [==============================] - 95s 2s/step - loss: 0.2971 - val_loss: 0.2805\n",
      "Epoch 5/100\n",
      "60/60 [==============================] - 90s 1s/step - loss: 0.2794 - val_loss: 0.2751\n",
      "Epoch 6/100\n",
      "60/60 [==============================] - 86s 1s/step - loss: 0.2703 - val_loss: 0.2724\n",
      "Epoch 7/100\n",
      "60/60 [==============================] - 86s 1s/step - loss: 0.3055 - val_loss: 0.2831\n",
      "Epoch 8/100\n",
      "60/60 [==============================] - 86s 1s/step - loss: 0.2663 - val_loss: 0.2599\n",
      "Epoch 9/100\n",
      "60/60 [==============================] - 88s 1s/step - loss: 0.2512 - val_loss: 0.2497\n",
      "Epoch 10/100\n",
      "60/60 [==============================] - 84s 1s/step - loss: 0.2441 - val_loss: 0.2422\n",
      "Epoch 11/100\n",
      "60/60 [==============================] - 84s 1s/step - loss: 0.2411 - val_loss: 0.2321\n",
      "Epoch 12/100\n",
      "60/60 [==============================] - 85s 1s/step - loss: 0.2352 - val_loss: 0.2324\n",
      "Epoch 13/100\n",
      "60/60 [==============================] - 85s 1s/step - loss: 0.2332 - val_loss: 0.2290\n",
      "Epoch 14/100\n",
      "60/60 [==============================] - 85s 1s/step - loss: 0.2297 - val_loss: 0.2250\n",
      "Epoch 15/100\n",
      "60/60 [==============================] - 85s 1s/step - loss: 0.2321 - val_loss: 0.2266\n",
      "Epoch 16/100\n",
      "60/60 [==============================] - 84s 1s/step - loss: 0.2250 - val_loss: 0.2230\n",
      "Epoch 17/100\n",
      "60/60 [==============================] - 85s 1s/step - loss: 0.2231 - val_loss: 0.2206\n",
      "Epoch 18/100\n",
      "60/60 [==============================] - 86s 1s/step - loss: 0.2210 - val_loss: 0.2186\n",
      "Epoch 19/100\n",
      "60/60 [==============================] - 84s 1s/step - loss: 0.2192 - val_loss: 0.2214\n",
      "Epoch 20/100\n",
      "60/60 [==============================] - 85s 1s/step - loss: 0.2175 - val_loss: 0.2164\n",
      "Epoch 21/100\n",
      "60/60 [==============================] - 84s 1s/step - loss: 0.2166 - val_loss: 0.2159\n",
      "Epoch 22/100\n",
      "60/60 [==============================] - 85s 1s/step - loss: 0.2139 - val_loss: 0.2133\n",
      "Epoch 23/100\n",
      "60/60 [==============================] - 86s 1s/step - loss: 0.2119 - val_loss: 0.2104\n",
      "Epoch 24/100\n",
      "60/60 [==============================] - 85s 1s/step - loss: 0.2115 - val_loss: 0.2120\n",
      "Epoch 25/100\n",
      "60/60 [==============================] - 85s 1s/step - loss: 0.2094 - val_loss: 0.2102\n",
      "Epoch 26/100\n",
      "60/60 [==============================] - 85s 1s/step - loss: 0.2064 - val_loss: 0.2119\n",
      "Epoch 27/100\n",
      "60/60 [==============================] - 85s 1s/step - loss: 0.2074 - val_loss: 0.2069\n",
      "Epoch 28/100\n",
      "60/60 [==============================] - 84s 1s/step - loss: 0.2022 - val_loss: 0.2065\n",
      "Epoch 29/100\n",
      "60/60 [==============================] - 84s 1s/step - loss: 0.2007 - val_loss: 0.2087\n",
      "Epoch 30/100\n",
      "60/60 [==============================] - 84s 1s/step - loss: 0.2009 - val_loss: 0.2080\n",
      "Epoch 31/100\n",
      "60/60 [==============================] - 84s 1s/step - loss: 0.1985 - val_loss: 0.2059\n",
      "Epoch 32/100\n",
      "60/60 [==============================] - 84s 1s/step - loss: 0.1966 - val_loss: 0.2058\n",
      "Epoch 33/100\n",
      "60/60 [==============================] - 84s 1s/step - loss: 0.1964 - val_loss: 0.2067\n",
      "Epoch 34/100\n",
      "60/60 [==============================] - 84s 1s/step - loss: 0.1949 - val_loss: 0.2021\n",
      "Epoch 35/100\n",
      "60/60 [==============================] - 84s 1s/step - loss: 0.1933 - val_loss: 0.2061\n",
      "Epoch 36/100\n",
      "60/60 [==============================] - 83s 1s/step - loss: 0.1905 - val_loss: 0.2092\n",
      "Epoch 37/100\n",
      "60/60 [==============================] - 83s 1s/step - loss: 0.1911 - val_loss: 0.2055\n",
      "Epoch 38/100\n",
      "60/60 [==============================] - 86s 1s/step - loss: 0.1887 - val_loss: 0.1992\n",
      "Epoch 39/100\n",
      "60/60 [==============================] - 85s 1s/step - loss: 0.1867 - val_loss: 0.2013\n",
      "Epoch 40/100\n",
      "60/60 [==============================] - 83s 1s/step - loss: 0.1869 - val_loss: 0.2039\n",
      "Epoch 41/100\n",
      "60/60 [==============================] - 85s 1s/step - loss: 0.1860 - val_loss: 0.2004\n",
      "Epoch 42/100\n",
      "60/60 [==============================] - 85s 1s/step - loss: 0.1839 - val_loss: 0.2035\n",
      "Epoch 43/100\n",
      "60/60 [==============================] - 83s 1s/step - loss: 0.1831 - val_loss: 0.2018\n",
      "Epoch 44/100\n",
      "60/60 [==============================] - 83s 1s/step - loss: 0.1816 - val_loss: 0.2020\n",
      "Epoch 45/100\n",
      "60/60 [==============================] - 83s 1s/step - loss: 0.1809 - val_loss: 0.2027\n",
      "Epoch 46/100\n",
      "60/60 [==============================] - 93s 2s/step - loss: 0.1821 - val_loss: 0.2000\n",
      "Epoch 47/100\n",
      "60/60 [==============================] - 86s 1s/step - loss: 0.1793 - val_loss: 0.1998\n",
      "Epoch 48/100\n",
      "60/60 [==============================] - 85s 1s/step - loss: 0.1807 - val_loss: 0.1980\n",
      "Epoch 49/100\n",
      "60/60 [==============================] - 84s 1s/step - loss: 0.1765 - val_loss: 0.2005\n",
      "Epoch 50/100\n",
      "60/60 [==============================] - 85s 1s/step - loss: 0.1771 - val_loss: 0.2036\n",
      "Epoch 51/100\n",
      "60/60 [==============================] - 85s 1s/step - loss: 0.1759 - val_loss: 0.1983\n",
      "Epoch 52/100\n",
      "60/60 [==============================] - 88s 1s/step - loss: 0.1731 - val_loss: 0.1974\n",
      "Epoch 53/100\n",
      "60/60 [==============================] - 91s 2s/step - loss: 0.1730 - val_loss: 0.1981\n",
      "Epoch 54/100\n",
      "60/60 [==============================] - 90s 2s/step - loss: 0.1720 - val_loss: 0.2006\n",
      "Epoch 55/100\n",
      "60/60 [==============================] - 86s 1s/step - loss: 0.1731 - val_loss: 0.2015\n",
      "Epoch 56/100\n",
      "60/60 [==============================] - 84s 1s/step - loss: 0.1713 - val_loss: 0.1994\n",
      "Epoch 57/100\n",
      "60/60 [==============================] - 84s 1s/step - loss: 0.1698 - val_loss: 0.1982\n",
      "Epoch 58/100\n",
      "60/60 [==============================] - 84s 1s/step - loss: 0.1688 - val_loss: 0.1990\n",
      "Epoch 59/100\n",
      "60/60 [==============================] - 84s 1s/step - loss: 0.1681 - val_loss: 0.1986\n",
      "Epoch 60/100\n",
      "60/60 [==============================] - 84s 1s/step - loss: 0.1666 - val_loss: 0.2006\n",
      "Epoch 61/100\n",
      "60/60 [==============================] - 84s 1s/step - loss: 0.1665 - val_loss: 0.1970\n",
      "Epoch 62/100\n",
      "60/60 [==============================] - 85s 1s/step - loss: 0.1656 - val_loss: 0.2009\n",
      "Epoch 63/100\n",
      "60/60 [==============================] - 86s 1s/step - loss: 0.1653 - val_loss: 0.1966\n",
      "Epoch 64/100\n",
      "60/60 [==============================] - 86s 1s/step - loss: 0.1646 - val_loss: 0.1983\n",
      "Epoch 65/100\n",
      "60/60 [==============================] - 85s 1s/step - loss: 0.1641 - val_loss: 0.2023\n",
      "Epoch 66/100\n",
      "60/60 [==============================] - 86s 1s/step - loss: 0.1642 - val_loss: 0.1950\n",
      "Epoch 67/100\n",
      "60/60 [==============================] - 85s 1s/step - loss: 0.1661 - val_loss: 0.2005\n",
      "Epoch 68/100\n",
      "60/60 [==============================] - 85s 1s/step - loss: 0.1696 - val_loss: 0.1983\n",
      "Epoch 69/100\n",
      "60/60 [==============================] - 85s 1s/step - loss: 0.1630 - val_loss: 0.1959\n",
      "Epoch 70/100\n",
      "60/60 [==============================] - 86s 1s/step - loss: 0.1608 - val_loss: 0.1962\n",
      "Epoch 71/100\n",
      "60/60 [==============================] - 86s 1s/step - loss: 0.1592 - val_loss: 0.1972\n",
      "Epoch 72/100\n",
      "60/60 [==============================] - 86s 1s/step - loss: 0.1585 - val_loss: 0.1967\n",
      "Epoch 73/100\n",
      "60/60 [==============================] - 85s 1s/step - loss: 0.1579 - val_loss: 0.1983\n",
      "Epoch 74/100\n",
      "60/60 [==============================] - 86s 1s/step - loss: 0.1570 - val_loss: 0.1993\n",
      "Epoch 75/100\n",
      "60/60 [==============================] - 85s 1s/step - loss: 0.1582 - val_loss: 0.1964\n",
      "Epoch 76/100\n",
      "60/60 [==============================] - 86s 1s/step - loss: 0.1567 - val_loss: 0.1979\n",
      "Epoch 77/100\n",
      "60/60 [==============================] - 86s 1s/step - loss: 0.1561 - val_loss: 0.1967\n",
      "Epoch 78/100\n",
      "60/60 [==============================] - 85s 1s/step - loss: 0.1550 - val_loss: 0.1974\n",
      "Epoch 79/100\n",
      "60/60 [==============================] - 84s 1s/step - loss: 0.1542 - val_loss: 0.1988\n",
      "Epoch 80/100\n",
      "60/60 [==============================] - 84s 1s/step - loss: 0.1543 - val_loss: 0.1995\n",
      "Epoch 81/100\n",
      "60/60 [==============================] - 84s 1s/step - loss: 0.1543 - val_loss: 0.2015\n",
      "Epoch 82/100\n",
      "60/60 [==============================] - 84s 1s/step - loss: 0.1543 - val_loss: 0.1978\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 83s 1s/step - loss: 0.1541 - val_loss: 0.1983\n",
      "Epoch 84/100\n",
      "60/60 [==============================] - 84s 1s/step - loss: 0.1530 - val_loss: 0.1961\n",
      "Epoch 85/100\n",
      "60/60 [==============================] - 83s 1s/step - loss: 0.1523 - val_loss: 0.1972\n",
      "Epoch 86/100\n",
      "60/60 [==============================] - 84s 1s/step - loss: 0.1525 - val_loss: 0.1991\n",
      "Epoch 87/100\n",
      "60/60 [==============================] - 84s 1s/step - loss: 0.1525 - val_loss: 0.1986\n",
      "Epoch 88/100\n",
      "60/60 [==============================] - 83s 1s/step - loss: 0.1511 - val_loss: 0.1963\n",
      "Epoch 89/100\n",
      "60/60 [==============================] - 83s 1s/step - loss: 0.1502 - val_loss: 0.1991\n",
      "Epoch 90/100\n",
      "60/60 [==============================] - 85s 1s/step - loss: 0.1498 - val_loss: 0.1994\n",
      "Epoch 91/100\n",
      "60/60 [==============================] - 86s 1s/step - loss: 0.1504 - val_loss: 0.1968\n",
      "Epoch 92/100\n",
      "60/60 [==============================] - 86s 1s/step - loss: 0.1496 - val_loss: 0.1974\n",
      "Epoch 93/100\n",
      "60/60 [==============================] - 85s 1s/step - loss: 0.1487 - val_loss: 0.1981\n",
      "Epoch 94/100\n",
      "60/60 [==============================] - 85s 1s/step - loss: 0.1479 - val_loss: 0.1964\n",
      "Epoch 95/100\n",
      "60/60 [==============================] - 84s 1s/step - loss: 0.1473 - val_loss: 0.1971\n",
      "Epoch 96/100\n",
      "60/60 [==============================] - 85s 1s/step - loss: 0.1471 - val_loss: 0.1979\n",
      "Epoch 97/100\n",
      "60/60 [==============================] - 84s 1s/step - loss: 0.1478 - val_loss: 0.1987\n",
      "Epoch 98/100\n",
      "60/60 [==============================] - 85s 1s/step - loss: 0.1468 - val_loss: 0.1981\n",
      "Epoch 99/100\n",
      "60/60 [==============================] - 85s 1s/step - loss: 0.1460 - val_loss: 0.1989\n",
      "Epoch 100/100\n",
      "60/60 [==============================] - 85s 1s/step - loss: 0.1453 - val_loss: 0.1998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x15caae02cd0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "model.fit(noisy_speech,IBM, epochs=100,validation_data=(valid_noisy_speech,IBM_validation), batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b9895033",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 26s 675ms/step\n"
     ]
    }
   ],
   "source": [
    "recon = model.predict(valid_noisy_speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fc7804d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio_stft(file_path):\n",
    "    audio, sr = librosa.load(file_path, sr=None)\n",
    "    stft = librosa.stft(audio, n_fft=1024, hop_length=512)\n",
    "    magnitude = np.abs(stft)\n",
    "    return magnitude.T,audio,magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4dd88abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_noisy_test=[]\n",
    "directory2 = \"C:/Users/dassu/Downloads/timit-homework/v/\"\n",
    "for filename in os.listdir(directory2):\n",
    "    if filename.startswith('vx') and filename.endswith('.wav'):\n",
    "        file_path = os.path.join(directory2, filename)\n",
    "        _,spectrogram,_ = process_audio(file_path)\n",
    "        valid_noisy_test.append(spectrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "09deb839",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_isft=[]\n",
    "for i in range(0,len(recon)):\n",
    "    noisy_signal = recon[i][:len(valid_noisy_test[i][1])] * valid_noisy_test[i].T\n",
    "    j= librosa.istft(noisy_signal.T, win_length=1024, hop_length=512)\n",
    "    noisy_isft.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d4b64a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_clean_test=[]\n",
    "directory2 = \"C:/Users/dassu/Downloads/timit-homework/v/\"\n",
    "for filename in os.listdir(directory2):\n",
    "    if filename.startswith('vs') and filename.endswith('.wav'):\n",
    "        file_path = os.path.join(directory2, filename)\n",
    "        _,spectrogram,_ = process_audio_stft(file_path)\n",
    "        valid_clean_test.append(spectrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "284b352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_snr(clean_signal, denoised_signal):\n",
    "    noise = clean_signal[:len(denoised_signal)] - denoised_signal\n",
    "    snr = 10 * np.log10(np.sum(clean_signal ** 2) / np.sum(noise ** 2))\n",
    "    return snr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "805fd302",
   "metadata": {},
   "outputs": [],
   "source": [
    "snr_values = []\n",
    "for i in range(len(clean_speech)):\n",
    "    snr = calculate_snr(valid_clean_test[i],noisy_isft[i])\n",
    "    snr_values.append(snr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d6222a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average SNR on validation set: 11.185748621324699 dB\n"
     ]
    }
   ],
   "source": [
    "average_snr = np.mean(snr_values)\n",
    "print(f\"Average SNR on validation set: {average_snr} dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62aaa9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio_test(file_path):\n",
    "    audio, sr = librosa.load(file_path, sr=None)\n",
    "    stft = librosa.stft(audio, n_fft=1024, hop_length=512)\n",
    "    magnitude = np.abs(stft)\n",
    "    return magnitude.T,stft,magnitude,sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5088b9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory3 = \"C:/Users/dassu/Downloads/timit-homework/te/\"\n",
    "valid_test_speech=[]\n",
    "sample_rate =[]\n",
    "for filename in os.listdir(directory3):\n",
    "    if filename.startswith('tex') and filename.endswith('.wav'):\n",
    "        file_path = os.path.join(directory3, filename)\n",
    "        spectrogram,_,_,sr = process_audio_test(file_path)\n",
    "        spectrogram=pad_audio(spectrogram)\n",
    "        sample_rate.append(sr)\n",
    "        valid_test_speech.append(spectrogram)\n",
    "valid_test_speech = np.array(valid_test_speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0a51199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 8s 595ms/step\n"
     ]
    }
   ],
   "source": [
    "recon = model.predict(valid_test_speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54e56871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 195, 513)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4e2b5da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_test_speech=[]\n",
    "directory3 = \"C:/Users/dassu/Downloads/timit-homework/te/\"\n",
    "for filename in os.listdir(directory3):\n",
    "    if filename.startswith('tex') and filename.endswith('.wav'):\n",
    "        file_path = os.path.join(directory3, filename)\n",
    "        _,spectrogram,_,_ = process_audio_test(file_path)\n",
    "        valid_test_speech.append(spectrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d03e6ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_isft=[]\n",
    "for i in range(0,len(recon)):\n",
    "    test_signal = recon[i][:len(valid_test_speech[i][1])] * (valid_test_speech[i]).T\n",
    "    j= librosa.istft(test_signal.T, win_length=1024, hop_length=512)\n",
    "    test_isft.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "17be804e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6eb0aacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"test_hw4_recons\"\n",
    "wav =\".wav\"\n",
    "for i in range(0,len(test_isft)):\n",
    "    sf.write(\"C:/Users/dassu/Downloads/timit-homework/reconstructed/\"+text+str(i)+wav, test_isft[i],16000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
